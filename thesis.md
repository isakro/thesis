--- 
title: "Computational modelling of the coastal Mesolithic in south-eastern Norway"
author: "Isak Roalkvam"
date: "2023-04-24"
site: bookdown::bookdown_site
documentclass: uiophdthesis
papersize: a4
bibliography: [book.bib]
output:
  bookdown::pdf_book:
    toc_depth: 3
    includes:
      in_header: preamble.tex
    latex_engine: xelatex
    citation_package: default
    pandoc_args: ["--csl", "saa.csl"]
bookdown::epub_book:
  pandoc_args: ["--csl", "saa.csl"]
link-citations: yes
classoption: oneside
nocite: | 
  @mangerud1974, @s√∏rensen2005
---

<!--chapter:end:index.Rmd-->

\mainmatter


# Introduction

One way to conceive of scientific inquiry is as a form of strategy by which we try to confront theoretical constructs with empirical observation, aimed at aligning our beliefs as reliably as possible with what is true [@godfrey-smith2003, 161]. A lot remains to be unpacked from this sentence. However, for now it is enough to note that the empirical side of this equation is a critical point for archaeology, as the fragmented and uncertain nature of the archaeological record means that there will always be a multitude of possible explanations that could account for any observed empirical pattern. Reducing this number of candidate explanations is first and foremost dependent on data, which in the case of archaeology are scarce. 

Establishing true explanations of a past social reality is at best exceedingly difficult, perhaps impossible, and must be the result of cumulative and recursive efforts from entire research communities over time -- it is not achieved by individual researchers. Accepting this social and cumulative nature of archaeological inquiry means that one can adopt a strategy to try to make one's research as open and amenable to scrutiny, extension, criticism and alternative approaches as possible. While easier said than done, an attempt at adopting such a strategy is done here. 

To accommodate the above points, this thesis aims to stringently explore and contrast empirical trends that have been deemed of importance for understanding past hunter-fisher-gatherer societies, drawing on the extensive material from the coastal Mesolithic of south-eastern Norway. Based on this, the project aims to culminate with the generation and presentation of some hypotheses concerning possible casual drivers behind the observed patterns. Exploration and stringency are explicitly voiced here for a couple of reasons. Exploration concerns an aspiration to approach the material with a degree of secession from previous hypotheses concerning the societal developments in the period, and to instead have observed empirical trends dictate the hypotheses presented. This can facilitate a freer investigation, transformation and combination of empirical patterns, as it reduces the risk of forcing the treatment of empirical patterns, consciously or not, towards a single explanation or end-goal. However, a complete break with previous beliefs is clearly neither possible nor desirable. For one these will in part have dictated how the material under study has been retrieved and recorded, how I will approach it, and is necessary for it to be possible to contextualise and make sense of any observed patterns. Stringency, and with it transparency of the analytical choices made, will make it easier for both me and others to follow the logic of the arguments presented, and make it easier to identify when and in what ways prior beliefs might have led an interpretation astray.   

As in many other areas of the world, the last few decades have seen a dramatic increase in the material generated by Norwegian archaeology. In terms of sheer number of sites and associated data, this is most marked for the coastal Stone Age material [e.g. @bergsvik2020; @damlien2021]. Given that this increase in material is achieved on the back of public spending, it is arguably a disciplinary obligation to utilise this data for research purposes. While there are many possible arguments for why archaeology is worthwhile at all, some more vague than others, the economic burden of archaeological practice is clearly easier to justify if the data we generate also informs the research we do. However, getting even a basic overview of this now vast material necessitates the use of quantitative and computational methods designed to handle, describe, explore, present, summarise and infer from such quantities of data. Following some early optimism in the 60s and 70s, such methods have, until recently, seen sporadic and relatively limited application for research purposes in Norwegian archaeology. 

Quantification offers standardisation and simplification, and by extension scalability and comparability. As with all disciplines concerned with the complexity of social life, whether past or present, archaeology also benefits from multiple perspectives that move between the nuance of particularities and the general trends illuminated by aggregated analysis. I would argue that the latter is at present still underdeveloped in Norwegian archaeology. With renewed and ongoing enthusiasm for such approaches, it is important that this is combined with a continually critical view of the answers these approaches can provide, and those which they cannot.

One of the great disciplinary benefits of archaeology, as compared to other disciplines concerned with the study of human societies, is by many argued to follow from the time depth it offers [e.g. @gamble2014]. Furthermore, while there are instances where the archaeological record allows what could be called glimpses into an ethnographic past of individual lives, the vast majority of the material we have access to is hampered by a degree of temporal uncertainty and lumping of events that necessitates a perspective that is developed to meet the nature and quality of the archaeological record on its own terms [@bailey2007; @perreault2019]. Both fully utilising the archaeological material and playing to the strengths of the discipline is thus dependent on knowledge of the quality of the material available to us, while also being dependent on developing methodologies fit for handling the material, given the empirical resolution it holds.

## Aims and research questions

The overarching goal of this thesis is to contribute to answering the following:

i) What is the extent and quality of the archaeological record from Mesolithic Norway? 
ii) What consequences does this have for our disciplinary agenda and potential for understanding the Norwegian Mesolithic?  

The answer to these questions is a disciplinary-wide undertaking, and no single thesis can hope to arrive at a final answer. To contribute to their elucidation, the thesis is centred on three more specific research questions. The first of the  can be viewed as largely instrumental in that it pertains to the degree and certainty with which we can fix the occurrence of our data on the calendar scale:

1) What chronological control do we have of the occupation of coastal Stone Age sites within the study area?

As @vankilde has put it: \'Chronology is the backbone of social interpretation\'. Following from an answer to this first question, the following two questions can therefore be explored:

2) What general patterns characterises the lithic inventories of the sites over time?
3) How is the frequency of sites distributed across time?

These latter questions have direct substantive implications, as their answer can be expected to be directly related to cultural developments. It should be noted that these are stated in an open and exploratory manner. What patterns are explored in the lithic assemblages and how any variation in the frequency of sites over time is interpreted in substantive terms are not done following some pre-defined framework but is rather approached in an inductive and exploratory manner.

## Study area

The study area of this thesis is delineated to coastal south-eastern Norway. No strict cultural-historical demarcation to surrounding regions is assumed, nor does that appear to be a have been the case throughout the Mesolithic. 

Furthermore, what is termed the coastal Mesolithic naturally didn't exist in isolation from inland regions. While the Mesolithic sites in Norway are concentrated to the coast [e.g. @bjerck2008], the reason behind the geographical limiting of the study is mainly analytical. First, while Mesolithic data is available from a wider region of south-eastern Norway, including inland areas, the last few decades have seen an virtual explosion of investigations in the coastal region between Horten municipality in the north east to Arendal in the south west. This has also been accompanied by geological studies to map the dramatic sea-level change that has impacted the Norwegian coast through the Holocene. The region thus represents an archaeologically well-sampled area where we also have good control of the trajectory of shoreline displacement. While the relevance of the findings in the study can be assumed to have relevance for surrounding areas, this subsection of south-eastern Norway therefore limits the spatial extent of the considered data. Furthermore, while this region holds high-quality archaeological material, investigated and recorded using modern methods, there is also an abundance of legacy data from the region, especially in the form of comparatively low-resolution and low-quality survey data. This constrained region thus also offers an excellent case-study for exploring the implications of dealing with data of wildly varying quality.   

Finally, methods and approaches developed for the coastal sites are not necessarily directly transferable to inland areas. This pertains most clearly to the concept of shoreline dating, which is based on dating sites with reference to their present altitude and the relative sea-level fall that characterises the region (see Paper 1). This offers a degree of large scale temporal control that is independent of the preservation of organic material for ^14^C-dates that is unique to the coast.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{figures/large_overview} 

}

\caption{The location of the study area in south-eastern Norway is indicated by the black frame south of Oslo. See the next chapter for a more detailed map and presentation of the study area.}(\#fig:map)
\end{figure}

## Model-based archaeology
Moving on from establishing a firmer grasp on the temporal dimension of the archaeological record in the two first papers, the final two papers of the thesis are more directly aimed at elucidating past cultural historical dimensions by tracking developments in empirical trends that have been linked to the understanding of past hunter-gatherer societies. This will be done within a framework of model-based archaeology. Models can be seen as partially independent representations of theory and data [@morrison1999]. By being a concrete realisation of an abstract theory in which its claims and conditions holds true, the model allows for a transfer of the logic of the theory to the modelled data, and a subsequent evaluation and manipulation of the fit between the two. Models are thus both descriptive and analytical, and can be seen as mechanisms or mediators allowing for the coupling of the two dimensions [e.g. @clarke1972; @kohler2007; @lake2015]. The inferential modesty called for above follows from the defining characteristic that \'All models are wrong, but some are useful\', as @box1979[202] famously put it. 

@barton2013 proposes a conscious and explicit modelling practice in archaeology for the same reasons. Traditionally, archaeological explanation is based on inductive and informal construction of narratives based on the inferential strategy of including as much data as possible and then arriving at a single explanation that is perceived to be the best fit in a *post-hoc* manner. This is argued to have a tendency to result in explanatory complacency and high personal investment into the credibility of any given explanation. By embracing the explicit uncertainty and fallibility that is a defining part of model-based approaches, this will therefore increase disciplinary progress, as it will lower the threshold for probing, adjusting and discarding one‚Äôs own models. 

## The hunter-gatherer model and the coastal Mesolithic of south-eastern Norway
The concept of hunter-fisher-gatherers will function as a foundational model from which to derive empirical avenues to be explored, and to propose possible causal drivers behind any observed patterns [cf. @warren2022, 29]. An example of a source from where this will be derived is the seminal work *The Lifeways of Hunter-Gatherers: The Foraging Spectrum* [@kelly2013]. In the introduction of the book, @kelly2013[4] states that it is aimed at providing its readers with \'some knowledge of the variation that exist among foragers and some idea of what accounts for it\'. Thus, while comprehensive in scope, @kelly2013 is also very explicit in the limitations of his review and states that while the hunter-gatherer term can be a useful heuristic and analytical unit for human societies, it carries no explanatory weight [@kelly2013, 22]. The societal variation among more recent hunter-gatherer societies is immense, and as foraging has constituted the predominant life-way for humanity for as much as, the variation that can be expected among past hunter-gatherer societies is comparatively vast [@singh2022]. Consequently, this thesis attempts to balance insights from hunter-fisher-gatherer studies more widely with an open and exploratory perspective. While preconceptions of hunter-fisher-gatherer societies necessarily dictates some of the analytical avenues taken and influence the type of questions that are asked, the aim is to have idiosyncrasies of the archaeological record in the context of coastal south-eastern Norway dictate the conclusions that are reached.

Another challenge in determining what empirical trends are of interest and how these are to be understood follow from the explicitly coastal setting of the study. Historically, both work on world prehistory and ethnography has focused on terrestrial contexts [e.g. @bailey2004; @yesner1980]. This issue also extends to the methodological realm, where for example the use of Geographical Information Systems (GIS) in archaeology has predominantly been used in terrestrial contexts [see e.g. @conolly2006]. This is especially pertinent for the study of the coastal Mesolithic of Scandinavia, which is characterised by dramatic sea-level change throughout the period [e.g. @bjerck2008; @astrup2018]. Out-of-the-box procedures are therefore not necessarily directly applicable and have to be adjusted to meet the demands of a geologically dynamic coastal context. 

## Open research and reproducibility

In making the case for open sharing practices in archaeological research, @marwick2017[426] compares the principle of artefact provenancing with dissemination of raw data and methods that underlie a study. Without knowing the origin and find-context of an artefact, it's archaeological value is practically none. Comparatively, by openly sharing data and programming code that underlies a study, other researchers can assess the procedures that have led to the results. Apart from facilitating an evaluation of its reliability, this allows others to extend on the analysis and the employed data, to learn and reconstruct how methods are implemented, and to attempt to repeat all or parts of the analysis themselves. Open research is thus beneficial to archaeology as a cumulative research endeavour as it will both increase the frequency of rejection and adjustment of proposed explanations, allow others to explore the foundations and inner workings of these explanations, and because it will increase the pace of method sharing, evaluation and adjustment. 

Furthermore, making scholarly publications free for anyone to read has been argued by many to lead to a democratisation of the discipline, as this will allow non-professionals, prospective students, non-academic collaborators and others without institutional access or the means to pay for access to the publications [e.g. @lake2012; @marwick2017a]. The aim of this thesis is thus to make all text, programming code, figures and underlying data freely accessible for anyone.

To this end, this thesis has been written in its entirety using the R programming language [@rcoreteam2021]. Unlike for example mouse-driven computational analyses, this means that an unambiguous record of the entire analytical pipeline is recorded in the form of programming scripts, moving from the initial loading and cleaning of raw data, through to analysis, visualisation and final reporting of results. Given the large amount of analytical choices that have to made in the course of any analysis, this can never be adequately presented in prose. Furthermore, what a researcher believes they have done need not correspond with what they have actually done. The high-resolution analytical record that is the programming script makes this entirely transparent. All data, programming code, figures and text used in this thesis is freely available in version-controlled online repositories on GitHub (https://github.com/isakro) and on persistent archiving services where the repositories are provided a digital object identifier (DOI). These have been organised using  Furthermore, Paper 3, which unlike the other papers is not published open access with the publisher, has been uploaded as a post-print to allow for free access. A complete overview with links to the various online archives associated with the individual papers and this synopsis is provided in Table \@ref(tab:op). 

\begin{table}

\caption{(\#tab:op)Overview of repositories and preprints.}
\centering
\begin{tabular}[t]{llll}
\toprule
Text & Preprint & GitHub repository & OSF repository DOI\\
\midrule
Synopsis & NA & github.com/isakro/thesis & 10.17605/OSF.IO/H3JFD\\
Paper 1 & osf.io/3x7ju & github.com/isakro/assessing.sealevel.dating & osf.io/h3jfd\\
Paper 2 & NA & github.com/isakro/shoredate & osf.io/7f9su\\
Paper 3 & osf.io/cqaps & github.com/isakro/exploring-assemblages-se-norway & \\
Paper 4 &  &  & osf.io/ehjfc\\
\bottomrule
\end{tabular}
\end{table}

## Overview of papers
### Paper 1: *A simulation-based assessment of the relation between Stone Age sites and relative sea-level change along the Norwegian Skagerrak coast*
The first paper of the thesis offers an approach for integrating the various sources of uncertainty associated with reconstructing the relationship between ^14^C-dated archaeological phenomena and past sea-level change. This is used to quantify the distance between Stone Age sites and the prehistoric shoreline within the study area. That coastal sites would have been located on or close to the prehistoric shoreline is a fundamental premise in Norwegian Stone Age archaeology. In combination with reconstructions of past shoreline displacement, this is frequently used to date the sites based on their altitude relative to the present day sea-level -- a method known as shoreline dating. The findings of the paper largely reflect the development proposed in the literature, with a predominantly shorebound coastal settlement in the Mesolithic, followed by a few sites being located some distance from the shoreline at the transition to the Early Neolithic (c. 3900 BCE) and a more decisive shift with the Late Neolithic (c. 2400 BCE). The result of this analysis is used to propose a formalised method for shoreline dating sites older than the Late Neolithic. This takes into account uncertainty as related to the displacement of the shoreline and the likely distance between sites and the shoreline when they were occupied. 

### Paper 2: *shoredate: An R package for shoreline dating Stone Age sites on the coast of south-eastern Norway*
Based on the findings from the first paper, the second paper of the thesis is a presentation of the R package *shoredate*, which provides tools for performing and handling shoreline dates along the Norwegian Skagerrak coast. The package has been written in compliance with the developmental framework presented by @wickhamnd, and is made freely available for anyone to install to R from the Comprehensive R Archive Network (CRAN): https://cran.r-project.org/package=shoredate. The paper itself gives a brief presentation of the package, but the publication of software with the *Journal of Open Source Software* also involves a useful and open review process of the software itself. Having published the package and released it as open source software on CRAN means that the method for shoreline dating is now available for researchers and student to employ, and that underlying code is available for anyone to explore, evaluate, criticise or extend upon. 

### Paper 3: *Exploring the composition of lithic assemblages in Mesolithic south-eastern Norway*
The second part of the thesis is aimed more squarely on elucidating past cultural history, as opposed to the more instrumental focus of the first two papers, aimed at establishing tools for improving our chronological . The third paper of the thesis is an exploratory study aimed at identifying variability in the contents of a set of lithic assemblages. The main goals of the paper is to evaluate the typo-technological framework currently in use in Norwegian Mesolithic research, and to assess the temporal development for variables that have been linked to variation in land-use and mobility patterns. It is demonstrated that elements of the so-called Whole Assemblage Behavioural Indicators [WABI, e.g. @clark2017] align with previous research into developments of mobility patterns in Mesolithic Norway, suggesting that the WABI could be a relevant framework also in this context. This is specifically reflected in a negative relationship between density of lithics, and the proportion of secondarily worked lithics in the assemblages over time, which is taken to reflect a transition from a more curated towards a expedient technological organisation with the transition from the Early Mesolithic (c. 8200 BCE). This is in turn argued to follow from a shift in land-use patterns and a overall reduction in mobility.

### Paper 4: *Comparing summed probability distributions of shoreline- and radiocarbon dates on the Norwegian Skagerrak coast*
Unpacking the complex interplay between environmental conditions, settlement patterns and population density has been deemed of fundamental importance to archaeological inquiry [e.g. @shennan2000; @french2016]. The fourth and final paper of the thesis is aimed at combining findings from the previous papers to evaluate the interplay between some empirical indicators suggested in the literature to be related to these dimensions. Concretely, the paper aims at elucidating the relationship between variation in relative population size as potentially reflected in the density of shoreline dated sites and the intensity of radiocarbon dates over time. 

## Structure of the thesis

This thesis is structured as six chapters in this synopsis, which contextualises the individual papers and point towards some future avenues along which these can be . These are followed by the four papers and the appendices associated with these. Following this introduction, the next chapter will lay out the environmental and archaeological background for the Mesolithic in the study region. Chapter 3 will present the major analytical perspectives that underlie the studies and the research questions that are posed. Chapter 5 lays out a model-based archaeology. In chapter 6 the papers are then cast within this model-based framework, both to clarify the arguments that underlie them, and to point out some future directions for how these can be fruitfully extended upon using a model-based framework. The final chapter concludes by summarising the major findings of the thesis



<!--chapter:end:01-introduction.Rmd-->

# The Mesolithic in south-eastern Norway

This chapter presents the context of the study, beginning with the overarching environmental developments relevant to south-eastern Norway, before general archaeological understandings and discussions of the period is presented. Focus is on the developments in south-eastern Norway, but insights from studies undertaken in Norway and Sweden more widely will be drawn on at times. The location of the study area is given in Figure \@ref(fig:overview) (see the introduction for a map displaying the location of the study region within Northern Europe).

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{figures/overview} 

}

\caption{Overview of study area. The darker grey marks the area where the material directly studied in this thesis stems from (see individual papers for details), indicated here by the borders of the municipalities from where the material originates. The counties outlined in black make up the administrative region of the University of Oslo, the Museum of Cultural History. The counties are given as they were defined before 2020, when several of these were combined due to administrative changes. The coastal region from around G√∂teborg to Vest-Agder is usually considered relatively uniform in terms of material culture throughout the Mesolithic.}(\#fig:overview)
\end{figure}


## Environmental setting

The environmental setting for the Mesolithic in Scandinavia is first and foremost defined by the end of the last glacial period with the transition to the Holocene around 9700 BCE, following the end of the Younger Dryas cold period [@skar2018; @mangerud2022]. This was caused by changes to the Earth's orbital parameters that led to an increase in solar irradiance [e.g. @berger1991]. Most pronounced of the resulting interrelated environmental developments is the melting of the Fennoscandian Ice Sheet, corresponding relative sea-level change, changes in atmospheric and oceanic circulation impacting temperature and precipitation, as well as the developments of the Baltic Sea, which has transitioned between being open and closed off from the North Sea. 

Climate reconstructions for the northern hemisphere based on oxygen isotopes from the Greenland ice cores indicate gradually increasing summer temperatures from c. 9700 BCE [@rasmussen2006; @rasmussen2007; @rasmussen2014], which generally corresponds, possibly with a slight time-lag, with developments in Fennoscandia and Norway [@seppa2009; @lohne2013; @lohne2014; @manninen2018]. This warming trend is interspersed by a few abrupt climate reversals, mainly caused by freshwater-forced weakening of thermohaline circulation. The first of these is the Preboreal oscillation (PBO) around 9400 BCE [@bjorck1997], while the most pronounced of the cooling events occurs c. 6200 BCE [the 8.2 ka BP event, e.g. @nesje2005; @wiersma2006; @seppa2009]. Following this, however, sediment cores from the North Atlantic indicate more environmental fluctuations than what is indicated in the Greenland ice cores [@nesje2014, 244].

Pollen-based reconstructions from Northern Europe indicate that the trend of increasing temperatures reached the local Holocene thermal maximum (HTM) c. 6000--2800 BCE, which is around 2000 years later than what is indicated in the Greenland ice cores [@seppa2009; see @s√∏rensen2014; @wieckowska-luth2017 for south-eastern Norway], likely reflecting a difference between regions primarily influenced by orbital forcing and those affected by the presence of melting ice sheets [@renssen2009]. This warming trend is evident from a range of records, including glacial fluctuations, where Scandinavian glaciers reached their most contracted state around 4600--4000 BCE [@nesje2009]. From around this point on the temperatures decline, with some fluctuations, towards the present, and the climate was increasingly characterised by being colder, wetter and more unstable [@seppa2009], also indicated by the reforming of glaciers between c. 4000--2000 BCE [@nesje2005; @nesje2009].

The increases in temperatures led to a development from Arctic to Boreal vegetation in the early Holocene of south-eastern Norway (see Table \@ref(tab:climate)), with a transition from pioneer species of bushes and grasses, to the establishment of open birch forest towards the end of the 10th millennium BCE [@birks2015; @h√∏eg2018, 194]. This was followed by the marked spread of hazel and pine c. 8500--8000 BCE, with elm and oak following a few hundred years later [@s√∏rensen2014, 202; @h√∏eg2018]. The spread of various deciduous trees increased in the Atlantic period, and from around 5500 BCE there was a marked increase in oak as well as the introduction of linden, the most heat-demanding of these tree-species [@h√∏eg2018, 199]. There is also some regional climatic variation in the coastal areas of south-eastern Norway, where the inner parts of the Oslo fjord has a more continental climate, characterised by warm summers, in which most of the precipitation falls, and cold winters. Towards the outer coastal areas the climate is more oceanic in character, with comparatively warmer winters with more precipitation and somewhat colder summers than in the inner coastal areas [@hafsten1965; @glorstad2010, 44--47]. A note should also be made here that anthropogenic influence on vegetation cover in the Mesolithic is evident from palynological indicators of fire management at some sites [e.g. @selsing2016; @wieckowska-luth2018], and is possibly also related to the spread of hazel through foraging of hazel nuts. However, human-induced changes to vegetation is most pronounced towards the end of the Neolithic with the wide adoption of agriculture [e.g. @hjelle2018; @wieckowska-luth2018; @h√∏eg2018, 199].

\begin{figure}

{\centering \includegraphics[width=1.05\linewidth,height=1.05\textheight]{figures/palaeo-maps} 

}

\caption{General developments of deglaciation, relative sea-level change and the Baltic Sea stages. A) Younger Dryas, c. 10 750--9700 BCE; B) Early Preboreal, c. 9700--9200 BCE; C) Late Preboreal, c. 9200--8700 BCE; D) Early Boreal, c. 8700--8000; E) Late Boreal, c. 8000--7200 BCE; F) Late Atlantic, c. 6500--4500 BCE. Spatial data from the European Prehistoric and Historic Atlas, Centre for Baltic and Scandinavian Archaeology (https://zbsa.eu/), with further references.}(\#fig:palaeo-maps)
\end{figure}

\begin{table}

\caption{(\#tab:climate)Approximate duration and general conditions of vegetational/climatic phases (based on S√∏rensen 2005, Mangerud et al. 1974)}
\centering
\begin{tabular}[t]{lll}
\toprule
Period & Duration & Conditions\\
\midrule
Preboreal & 9500--8200 BCE & Warm and dry\\
Boreal & 8200--7000 BCE & Warm and dry\\
Atlantic & 7000--3800 BCE & Warm and wet\\
Subboreal & 3800--750 BCE & Colder and dry\\
Subatlantic & 750 BCE--Present & Cold and wet\\
\bottomrule
\end{tabular}
\end{table}

Mapping the palaeoceonographic developments of Skaggerrak, @gyllencreutz2006 identify four major developmental stages. From the period 13 000--11 000 BCE, Skagerrak is a large fjord, enclosed by land to the south and the ice-front to the north. Warmer Atlantic water impacts Skagerrak already from the start of this period, but the circulation is likely to have been weak. At around 11 000 BCE drainage started from the Baltic Sea, at this stage the Baltic Ice Lake, through the √ñresund strait to the south [@andren2011]. Glacial meltwater entered Skagerrak through the √ñresund strait until the final drainage of the Baltic Ice Lake around 9700 BCE. The resulting Baltic Sea stage, which thus corresponds with the onset of the Holocene, is termed the Yoldia Sea. The Yoldia Sea had open contact with Skagerrak through straits in south-central Sweden through Lake V√§nern, north of G√∂teborg, impacting the circulation patterns of Skagerrak [@gyllencreutz2006]. Due to isostatic uplift, the Baltic Sea was again closed off from the ocean around 8700 BCE, marking the onset of the Ancylus Lake stage, in which the Baltic sea was a large freshwater lake until c. 6900 BCE. 

In the period from 7500--6100 BCE the present day circulation patterns are established in Skagerrak. The opening of the English Channel and the isolation of Doggerbank, starting from around 8000 BCE--7000 BCE, resulted in an increased Atlantic inflow to Skagerrak, and in the period from around 8100--7000 BCE the gradual opening of the √ñresund and Danish Straits established an opening to the Baltic Sea in the south. In combination, these developments resulted in the mixing of saline and fresh water, and @gyllencreutz2006 consider most major features of the current circulation system to have been established by c. 6500 BCE.   

The above developments have framed the population dynamics of terrestrial and marine fauna in south-eastern Norway through the Mesolithic, where the transition from Arctic to more temperate conditions led to the displacement of cold-tolerant terrestrial species, and the salinity and temperature in Skagerrak similarly impacted marine species [e.g. @breivik2014; @damlien2021, 24 with references therein]. In the transition towards a Boreal climate, Arctic species such as reindeer and polar fox moved to the mountain regions, while species such red deer, roe deer, elk, beaver and boar increasingly populated the forest-covered landscape in the low-lands [@hufthammer2006].  @jonsson has argued that the very first humans to have colonised northern Scandinavia would have been limited to the explotation of seal, as these would have been the first species to 

<!-- interspersed with cold events c. 10 300 cal BP, c. 9200 cal BP and 8200 cal BP -->

### Sea-level change
As the dramatic sea-level change that has occurred within the study area throughout the Mesolithic is of central importance to this thesis, an extra emphasis is placed on these developments here.

Following the retreat of the ice

The marine limit, that is, the highest elevation of the sea following the retreat of the ice, is around 220 meters above present sea-level (masl) in the innermost part of the Oslo fjord. In Horten, at the northern limit of the study area for this thesis, the marine limit is c. 182 masl [@romundset2021; @berg-hansen2022]. In the centre of the study area, in Porsgrunn, the marine limit is around 155 masl [@s√∏rensen2014], and furthest to the south, in Arendal, c. 83 masl [@romundset2018].   

Furthermore, the 

Depending on its magnitude, sea-level change can impact not only the habitational suitability of any individual location, but can have far-reaching effects that impact shoreline morphology, drainage systems and [e.g. @astrup2018; @gross2018]. While the at times dramatic effects of these changes would have required a response from human populations inhabiting the impacted areas, it is by no means given that these would have negative consequences societal effects, nor that this would be have been perceived as something negative. In fact, areas impacted by sea-level change can become increasingly attractive for hunting, fishing and gathering precisely because of these factors. As with any environmental change, how sea-level change impacts the population of any given area will thus depend on a wide range of factors pertaining to the amplitude of shoreline displacement, the topographic setting, and the nature of the societal systems which respond to these changes.

Sea-level regression would have had the consequences that present-day fjords would have been wider in prehistory, and other fjords, straits and waterways that are closed off today would have been present. In south-eastern Noway, the sea-level regression has impacted the shoreline morphology in various ways and at various scales from the fact that the Oslo fjord itself would have been a larger bay, while for example individual straits would have been closed off or have become narrower [e.g. @glorstad2010; @mj√¶rum2022].

## Archaeological background

Having presented the general environmental developments of the period, the following section gives an outline of how chronological and societal developments in the Mesolithic of south-eastern Norway have been characterised and understood archaeologically. The first focused research on the Norwegian Mesolithic is ascribed @hansen1904, who studied the material that @br√∏gger1905 later saw as a defining element of the N√∏stvet culture [@bjerck2008, 61]. In 1909, Nummedal made discoveries of flint artefacts in western Norway that were deemed likely to have an earlier date than the N√∏stvet material [@rygh1911; @nummedal1912], and which led to the subsequent definition of another cultural unit termed Fosna [@nummedal1923]. Nummedal later also discovered material in northern Norway that had parallels with, but was considered distinct from Fosna and was given the label Komsa [@nummedal1927]. While the geographical and temporal relationship between these cultural units were recognised as unresolved and was subject to much debate, the common understanding was for many decades that southern Norway was defined by the chronologically sequential phases Fosna and N√∏stvet, while Komsa was seen as defining of the entire Mesolithic period in northern Norway [see e.g. @indrelid1978, 147]. With renewed debates in the 1970s, that were arguably founded on a better understanding of lithic technology [@bjerck1994], significant alterations to the chronological framework was proposed. @mikkelsen1975 suggested a quadripartite division of the Mesolithic in south-eastern Norway by dividing the period into the Early Mesolithic Fosna phase, the Middle Mesolithic T√∏rkop phase, and the Late Mesolithic phases N√∏stvet and Kje√∏y. While there have been subsequent discussions and adjustments [e.g. @jaksland2001; @gl√∏rstad2004], the chronology used to characterise the Mesolithic of south-eastern Norway has generally followed along the lines of the framework used by @glorstad2010[23, see Table \@ref(tab:tab1)]. 

In a comprehensive reassessment that also includes results from the last decades of excavations, @reitan2022 has recently suggested a new chronological framework for the Mesolithic period in south-eastern Norway [also @reitan2016]. As his focus has mainly been on technological and typo-chronological developments, and given their recent date of publication, this framework has yet to be comprehensively evaluated in terms of correspondence with other societal developments. The presentation of major chronological trends in the sections below thus follows the traditional periodisation, as this underlies most of the cited studies.  As the papers for this thesis largely operate independently of this periodisation, as will be presented in more detail in later chapters, the chronological framework used here is mainly meant to set a heuristic and general frame of reference for the developments that are believed to have characterised the Mesolithic in the region.

<!-- However, in the discussion chapter, the results of this thesis will also be seen in relation to the framework suggested by Reitan. -->

\begin{table}

\caption{(\#tab:tab1)Chronological framework. Gl√∏rstad's (2010) divison of phases reflects the more traditional framework, to which Reitan (2016, 2022) has recently suggested considerable adjustments.}
\centering
\begin{tabular}[t]{ll}
\toprule
Gl√∏rstad (2010) & \\
Early Mesolithic, Fosna Phase & 9300‚Äì8200 BCE\\
Middle Mesolithic, T√∏rkop Phase & 8200‚Äì6300 BCE\\
Late Mesolithic, N√∏stvet Phase & 6300‚Äì4600 BCE\\
Late Mesolithic, Kje√∏y Phase & 4600‚Äì3800 BCE\\
 & \\
Reitan (2022) & \\
Single-edged point phase & 9300‚Äì8600 BCE\\
H√∏gnipen point phase & 8600‚Äì8300 BCE\\
Microlith Phase & 8300‚Äì7000 BCE\\
Pecked Adze Phase & 7000‚Äì5600 BCE\\
N√∏stvet Adze Phase & 5600‚Äì4500 BCE\\
Transverse Arrowhead Phase & 4500‚Äì3900 BCE\\
\bottomrule
\end{tabular}
\end{table}

Before the 1990s, the Mesolithic material from south-eastern Norway was mainly derived from stray finds of axes [@bj√∏rn1943; @hagen1946] and the excavation of a few individual sites [@mikkelsen1975; @mikkelsen1999; @√∏stmo1976]. From around the 1990s and onwards, there has been a dramatic increase in excavations of Mesolithic sites in south-eastern Norway. This extends from smaller scale investigations of individual sites [see @damlien2021 for a recent overview], to larger multi-year projects in the counties of √òstfold [@gl√∏rstad], Hedmark [@boaz1999; @stene2010; @stene2019], Vestfold and Telemark [@melvold2014b; @jaksland2014; @solheim2017b; @berg-hansen2022], Vest-Agder [@ballin1995], √òst-Agder [@reitan2018c], and Akershus [@ballin1998; @jaksland2001; @rosenvinge2022]. The material used for this study stems from Vestfold, Telemark and Vest-Agder (Figure \@ref(fig:overview)). This study area is located firmly within what has been considered an area of comparable material culture throughout the Mesolithic in the northern Skagerrak area.

### The Early Mesolithic (9300--8300 BCE)

The first human presence in Norway is recorded from around 9300 BCE, which marks the start of the EM. A central discussion has concerned whether people first migrated into the area of present-day Norway from a route along the coast of western Sweden, from the north-east along the North-Norwegian coast [@bj√∏rn1929], or across the Norwegian trench to south-western Norway from the North Sea Plain [\'Doggerbank\', @odner1966, 135--136]. The most recent evidence suggest that a crossing from Doggerbank would not have been feasible due to the distances involved at the time [@glorstad2016; @glorstad2017]. The present consensus is therefore that the earliest human dispersal into present-day Norway is likely to have originated on the coast of western Sweden around 9500--9300 BCE [e.g. @bang-andersen2012; @fuglestvedt2012; @glorstad2020; @bjerck2008; @bjerck2021]. From here, human occupation is believed to have rapidly extended along most of the Norwegian coastline, while a north-eastern migration reached Kola and northern Norway some time before 9000 BCE [@manninen2021]. These two routes are associated with the genetically defined \'western\' hunter-gatherers that migrated from the south, and \'eastern\' hunter-gatherers migrating from the north [@gunther2018], each identifiable also in terms of distinct material culture and associated technological traits [@manninen2021].

 <!-- (f.eks. Bjerck 2008c:74; Gl√∏rstad 2010a:91-93) -->

Pioneer sites in Norway and Western Sweden have traditionally been ascribed the archaeological cultures or techno-complexes Fosna and Hensbacka, respectively. Today these are seen as representing the same phenomena [e.g. @bjerck2008, 75]. Fosna/Hensbacka sites are to have fairly homogeneous lithic inventories, and are held by many as having a common origin tracing back to South-Scandinavian and North-European Palaeolithic Ahrensburg groups [e.g. @bjerck2008; @schmitt2009; @bang-andersen2012; @fuglestvedt2012]. The analyses of artefact inventories, the presence of high-quality South-Scandinavian flint, and the chronological support of radiocarbon dates and shoreline dates have in sum led to the consensus on this continental connection (e.g. @fischer1996; @schmitt2006; @fuglestvedt2007; @fuglestvedt2009; @bang-andersen2012; @glorstad2016). 

The similarities has even led @fuglestvedt2012[8] to propose that the terms Fosna/Hensbacka be abandoned altogether, in favour of Ahrensburg, as this would accentuate the continental elements that appear so defining for these pioneer sites. Although this has been met with varying degrees of enthusiasm [e.g. @bjerck2008, 73; @√•stveit2014, with comments], particularly by those emphasising the strong marine orientation of the Fosna/Hensbacka, there has also been the occasional use of variations such as 'coastal Ahrensburg' to denote the Fosna/Hensbacka [@pr√∏sch-danielsen1995]. Following a recent analysis of lithic inventories from the transition from the Palaeolithic to the Mesolithic in Northern Europe, and comparison with Fosna/Hensbacka sites in Norway and Sweden, @berg-hansen2017[] has argued that the Fonsa/Hensbacka sites have a clear similarity with EM Maglemose sites in Denmark. While there are elements of this technology that point back to the Ahrensburg, there is also a clear break with the Palaeolithic technology. She therefore argues that these societies should, as with the Maglemose, be considered Mesolithic and not a northern continuation of Palaeolithic life-ways. At any rate, these discussions do go to show that there is a clear affinity between the first human population on the Scandinavian Peninsula and continental hunter-gatherer groups.

To account for the apparent pan-regional homogeneity that is to characterise the archaeological material in the earliest part of the Mesolithic, a central question is by what process Norway and western Sweden were initially colonised [e.g. @bjerck2009; @schmitt2009; @bang-andersen2012; @fuglestvedt2012; @glorstad2016; @berg-hansen2017]. An important aspect in this regard is the fact that the coastal areas in western Norway were largely ice-free around 3000 years before the first recorded human presence in Norway [@mangerud2022], and must have been rich and desirable areas in terms of resources early on [@bjerck1994; @bjerck2009; @bang-andersen2012; @glorstad2016]. 

Bjerck [-@bjerck1994; @bjerck2008, 85; @bjerck2009; @bjerck2017] has explained the fact that people did not start exploiting these regions until around 9300 BC with reference to less developed marine subsistence strategies among North-European hunter-gatherer groups. The coastal location of the majority of Fosna/Hensbacka sites will undoubtedly have necessitated extensive adjustment to marine environments, including by the use of boats. Following the delay induced by this, the hunting of seal, conceptually not that different from the hunting of large terrestrial mammals, might have spurred an increased development of boating technology, while at the same time lending itself to the continued use of a continental artefact inventory [@bjerck2009; @bjerck2016]. Proficient and effective use of boats might in turn have resulted in a relatively rapid colonisation of Fosna/Hensbacka areas, possibly as fast as over a period of only 200--300 years [@bjerck1994; @bang-andersen2012], providing a possible explanation for the homogeneous assemblages. These could reflect mobility of a kind not allowing for familiarisation with local resources for tool production, nor the development of distinct inventories adjusted to various geographical settings. The assemblages might therefore represent a sort of catch-all tool-kit, suitable to meet the variable demands of a \'pioneer condition\' [@bjerck2017; see also @breivik2016]. Furthermore, @berg-hansen2017[232] has argued that the homogeneity in the lithic inventories could be related to relatively high population numbers with closely knit social ties, which in combination has enabled this technological conservatism. Homogeneity and continuity in lithic technology over vast expanses of Scandinavia would on this view be difficult to envision with a thinly spread population consisting of more isolated groups.

@glorstad2016 places more emphasis on how the process of deglaciation might have delayed human migration to present-day Norway, as opposed to the logistic challenges these areas might have represented for North-European hunter-gatherer groups. The morphology of the Oslo fjord means that although large coastal areas in Norway were ice-free in the first centuries of the Holocene, the inner most parts of the fjord would have been covered by ice further up in time. Although the precise timing for deglaciation of the inner parts of the fjord is not precisely dated [@mangerud2022, 64], this would have partly obstructed the further spread of environmental elements from the continent. The fjord itself would also have been a broader bay, making any crossing by boat a formidable, if not impossible task before the protective archipelago could be followed along at least most of the coastline. Parallel to this, isostatic uplift eventually resulted in the decline of the central coast of Western Sweden as a prime location in terms of marine resources [@schmitt2009]. This was due to the closing off of straits connecting the North Sea and present day Baltic Sea -- a process that concluded around the later parts of the Preboreal. As a result, southern foraging groups might have found it increasingly necessary and convenient to extend northwards along the coast [@glorstad2016]. Previous explanations such as that of Bjerck might therefore have overemphasised the unique challenges posed by the geographical setting of Norwegian coastal landscapes. This debate is by no means concluded, however, and authors such as Bjerck [-@bjerck2013, @bjerck2017] and @bang-andersen2013 have met many of Gl√∏rstad's suggestions with reluctance, including what they consider a downplay of the logistical demands that these coastal areas must have presented, also following the retreat of the ice.

In general, the Early Mesolithic in Norway is understood as characterised by highly mobile groups, reflected by what is typically interpreted at small, homogeneous sites located at exposed locations in the landscape [e.g. @bjerck1994; @n√¶r√∏y2000; @bjerck2008; @fuglestvedt2012], and lighter, more expedient dwelling structures in the form of tent-like structures [e.g. @√•stveit2009; @fretheim2017, 219]. As there is little organic material on which to base inferences on subsistence from this period, there is little direct evidence to go on when attempting to determine what available resources made up the diet of people in Norway in the first centuries of human occupation. Given the North-European origin of the first humans in Norway, the hunting of reindeer has been suggested to be a possible driver behind the initial colonisation. However, the EM sites are predominantly found along the coast, and so there is little doubt that aquatic resources have played a central role [@indrelid1978; @bjerck2008; @bang-andersen2012; @fuglestvedt2014; @svendsen2018]. 

However, it can not be excluded that a variety of species of terrestrial mammals, fowl and flora have also been important constituents of the diet [@√•stveit2014; @fuglestvedt2014; @mansrud2018]. While the settlement is focused on the coast, there is also a presence in the inland and mountain regions of south- and north-western Norway from a very early stage, which is believed to have been related to the hunting of reindeer [@hagen1963; @bang-andersen2012; @breivik2016; @svendsen2018]. @persson2018[207] argues that the contemporaneous establishment of coastal and inland sites is an indication that pioneer populations were neither specialised inland reindeer hunters nor specialised marine foragers who then later expanded their resource base. Furthermore, @mansrud2018 argue that the presence of microliths, which is to be indicative of bow-and-arrow technology, combined with the environmental backdrop of increasing temperatures, the reduced oceanic influence from the melting ice sheet, and the establishment of the Norwegian Atlantic Current, in sum points towards a wider spectrum of resource exploitation. This as opposed to what has in the literature sometimes been cast in a dichotomous and one-sided focus on either seal or reindeer [see @√•stveit2014 with comments].   

Given the lack of direct evidence for subsistence strategies, the analysis of settlement patterns and overall palaeoecological developments is typically drawn on to make general inferences regarding the question of resource exploitation. The coastal EM sites have been characterised as having a tendency to be situated on small islands [@nyland2012; @breivik2014], and been exposed to the sea [@bang-andersen2003; @breivik2014]. This is argued to reflect the importance of marine mammals, especially seal, in the EM.

As a counterpoint, there have been demonstrated several exceptions to the tendency of EM sites to be situated at exposed locations and on islands [@darmark2018], and some authors have argued that the degree of site homogeneity and differences in settlement patterns compared to later periods has been exaggerated or is not properly understood [@glorstad2013; @√•stveit2014; @viken2018; see also @damlien2021, 79--81]. Furthermore, in a recent study I found that the settlement patterns in a subregion of south-eastern Norway was fairly similar across the EM, MM and LM [@roalkvam2020]. Of the considered variables, the most important driver of settlement patterns was found to be degree of exposure, where the sites were found to be located with relatively open immediate surroundings, while at the same time being sheltered from larger stretches of open sea. However, one of the locational patterns that was not considered was the location of the sites within the wider landscape. The term exposure has been used to denote both how commanding the view would have been from the sites and how exposed the sites would have been to wind and wave-action [@svendsen2014], but has also pertained to their location relative to deeper fjords and outermost coast [e.g. @lindblom1984; @jaksland2001; @bergsvik2001; @bjerck2008; @nyland2012; @svendsen2018]. It has been argued that EM sites would have mainly been located on the outer coast, and that the fjords were not utilised until a later stage, which could reflect a resource base focused on marine mammals.

Breivik [-@breivik2014; @breivik2020] has recently focused on diachronic variation through the EM. She argues that while the PBO was defining for the conditions for earliest human colonisation of Norway, with favourable conditions for Arctic marine species such as seal, the establishment of the Norwegian Atlantic Current led to a more stable marine environment from c. 8800 BCE. This change in environmental conditions could be related to what she identifies as a shift in settlement patterns and site types around the middle of the EM. This diachronic distinction underscores the point that treating the EM as a unified aggregative temporal unit could suppress important temporal variation within the phase, variation that is potentially better accommodated by the separation that @reitan2022 makes between the Single-edged point phase and the H√∏gnipen point phase (Table \@ref(tab:tab1), see also the next chapter).

### The Middle Mesolithic (8300--6300 BCE)
While the Middle Mesolithic (MM) was defined as a separate typo-chronological phase in the 1970s, @bjerck2008[92--98] stated as late as 2008 that the period was associated with a limited archaeological material, thus posing an analytical challenge. This is in part related to sea-level transgressions in this period along the coast of southern and western Norway. In south-eastern Norway, which has not been subject to sea-level transgression, the lack of MM material could in part be related to the fact that MM sites are located at elevations that have historically not been impacted by the expansion of infrastructure, and thus not targeted by archaeological investigations [@jaksland2001, 27]. This picture has changed dramatically over the last couple of decades, and in addition to the excavation of individual sites, an expansive MM material has been investigated within the study area of this thesis in larger projects such as E18 Bommestad--Sky [@solheim2013c], Vestfoldbanseprosjektet [@melvold2014b], E18 Tvedestrand--Arendal [@reitan2018c], and Intercity Vestfold [@berg-hansen2022].

Discussion pertaining to the MM have in part been concerned with whether the period has more in common with the highly mobile societies of the EM or with what was is typically seen as more sedentary or semi-sedentary LM societies [e.g. @bang-andersen2005; @glorstad2010; @mansrud2014; @solheim2016; @berg-hansen2022; see also the third paper of this thesis, @roalkvam2022]. There is a clear shift in material technology around the end of the 9th century BCE [@s√∏rensen2013; @damlien2016; @eymundsson2018; @solheim2020a; @bergsvik2015; @mansrud2018], which coincides with a genetic mix between the populations originally migrating to the Scandinavian Peninsula from the south and those extending southwards from the north-east [@gunther2018; @manninen2021; @skar2022]. However, several aspects of these societies are still believed to show similarities with the EM. For one, MM sites have, as with the EM sites, traditionally been seen as remnants of shorter stays [@jaksland2001; @mansrud2014, 87]. Furthermore, based on sites from northern Vestfold, @berg-hansen2022[662] have argued that coastal settlement patterns in the start of the MM appear to be a continuation of those from the EM, characterised by a site location concentrated to the outer coast. 

However, other aspects of the MM show a clearer break with the preceding EM. @bjerck2008 notes that the MM is characterised by a degree of regionalisation in the lithic material that is not evident in the EM material. One feature of the lithic inventories is an increased use of locally occurring non-flint material, which is often held to indicate an increase familiarity and attachment to local areas [@berg1997, 109; @jaksland2001, 110]. Furthermore, recent investigations in south-eastern Norway has revealed what has been interpreted as integrated settlement systems consisting of sites with different functions, as opposed to the homogeneous sites that are to characterise the EM [@solheim2013b; @solheim2016; @berg-hansen2022].

While there appears to be a high diversity of dwelling structures from the MM in Norway, including some that are reminiscent of those from the EM [e.g. @granados2023], substantial sunken dwelling-structures dated to the MM have also been identified [@bjerck2008; @solheim2013; @mj√¶rum2018; @fretheim2017, 220; @berg-hansen2022]. The higher investment of time and resources that these dwelling structures represent has been taken by many to indicate an increased attachment to the area in which they were built [e.g. @bjerck2008; @√•stveit2009; @fretheim2016; @solheim2016; @berg-hansen2022]. 

Furthermore, the MM sees an increased exploitation of inland and mountain regions [@indrelid1994; @boaz1999; @persson2009; @selsing2010; @persson2018], and it has been suggested that a separate inland population is established in this period in south-eastern Norway [@damlien2018]. The exploitation of red deer, reindeer and especially elk appears to be of central importance to these inland sites, a practice that appears to be firmly established around 6500 BCE [@mj√¶rum2018]. The comparatively low number of EM sites in the inland areas of Eastern Norway should also be seen in light of the fact that the ice sheet did not melt entirely until probably around 8000--7500 BCE [@mangerud2022, 65], and that environmental conditions conducive of a larger elk population with stable migratory routes was established after c. 7000 BCE [@mj√¶rum2018, 188]. However, @boaz1999[132--133] has argued that human occupation in these inland regions followed some time after productive biotopes were already established in parts of this area, and therefore that this delay mainly reflects cultural factors rather than environmental ones.

While there are several taphonomic factors that might bias the preservation of faunal material when evaluating dietary changes through the Mesolithic, this material does appear to offer support for changes in the resource base from the EM to the MM. In their review of the osteological material from MM sites in western Sweden and south-eastern Norway, @mansrud2018 find support for a comparatively broad-spectrum resource-base in the MM that includes the exploitation of fish, birds and both terrestrial and marine mammals. While fish and marine mammals appears to have been fundamental to    

While the wide exploitation and specilisation towards fishing has traditionally been argued to be a characteristic of later Mesolithic phases, and be related to an increase in sedentism [@mj√¶rum2020, 289], finds of fish hooks and assemblages associated with a dominating abundance of fish remains has pushed back this date to the MM [e.g. @bergsvik2015; @ritchie2016; @boethius2018; @boethius2020; @mj√¶rum2020]. Whether indications of extensive exploitation of fish can be pushed even further back in time remains to be determined, but given the taphonomic bias that impacts the preservation of fish bone, it is not unthinkable that the antiquity of extensive fishing in the Norwegian Mesolithic remains underestimated [@bergsvik2020b, 240].

Unlike the genetic changes and changes in flint technology that are believed to be more abrupt around the transition to the MM, @berg-hansen2022 argue that other aspects such as the transition to different settlement patterns and an increase in the use of non-flint material is a more gradual process. This highlights the fact that while it appears relatively established that migration events resulted in pervasive changes to the Mesolithic societies in south-eastern Norway around the transition to the MM, a lot remains to be understood concerning the process and timing by which this happened, and the consequences it had at the societal level. Moves to challenge the established chronological framework, such as that proposed by Reitan [-@reitan2016; -@reitan2022], can potentially help in an endeavour to untangle these, and accepting that different societal processes might operate and be recognisable at differing temporal scales is also important in this regard (see also the next chapter).    

### The Late Mesolithic (6300--3900 BCE)

The transition from the MM to LM is defined by. As a result of the dicussions pertaining to the relationship between the MM and the LM, the LM is now in many respects seen as a period in which societal developments intensifies and become 

The period also sees an increase in the use of local non-flint material, especially represented by the N√∏stvet core adze, and a few sites interpreted as specialised adze-production sites date from this period [@glorstad2011; @eigeland2014]. The western Swedish equivalent to the N√∏stvet phase and N√∏stvet adze is denoted Lihult, and, as with preceding periods, these are now considered to represent the same phenomena [@gl√∏rstad2011]. However, in Reitan's [@reitan2016; @reitan2022] new re-evauluation of the material, he has not found indications that the typological indicators that are to be clear markers of the N√∏stvet phase occur earlier than around 5600 BCE. As a potential counterpoint to the gradual intensification of societal traits that are first introduced in the MM, the transition to the classic N√∏stvet material record appears to represent a clear and relatively sudden break [@reitan2022].

The transition to the LM phase Kje√∏y, occurring around 4600--4500 BCE (Table \@ref(tab:tab1)) is indicated by a reduction and change in the techniques used in the production of adzes, as well as the introduction of flint projectile points [@reitan2022]. Based on technological changes [@eigeland2015] and apparent changes in relative population numbers [@nielsen], it has been suggested that new people have migrated to the coastal areas of south-eastern Norway from the south in this period. The Kje√∏y phase and its relation to the preceding periods must, however, be considered relatively poorly understood as there has historically been limited material available, and as the phase not received the same amount of focused research as other Mesolithic periods [@damlien2021, 100].

Taken as a whole, the LM sites in Eastern Norway are argued be characterised by an increased variation in size, artefact inventories and topograhical location [@lindblom1984], which includes several sites that are interpreted as the result of repeated stays of a longer duration [@gl√∏rstad2010]. Furthermore, the period has also been argued to be characterised by increased social differentiation and the establishment of territories within the region [@jaksland2001, 119--210; @fuglestvedt2008; @glorstad2010, 160--165].

In Western Norway, Bergsvik [@bergsvik2001; @bergsvik2002] noted that large LM sites were located close to good fishing locations along straits, and sees this as evidence for an increased degree of sedentism towards the later parts of the Mesolithic [@bergsvik2006]. Furthermore, zooarchaeological evidence from rock shelters appear to indicate an increased specialisation towards fishing in the LM [@ritchie2016], and @bergsvik2016 argue that a shift towards sedentism in western Norway occurs around 6100 BCE. A similar 


Blade production in the Late Mesolithic is characterised by the introduction of handle cores [@eigeland2015]. As pointed out by @solheim2020[4], this involves a shift from cores that will result in blades of gradually diminishing size as the core is exhausted in the EM and MM, to cores that result in blades of a uniform and comparatively small size (i.e. microblades). 

The end of the Mesolithic is defined by the introduction of pottery to the sites, and potentially. 

<!--chapter:end:02-background.Rmd-->

# Analytical background

This chapter presents underlying analytical concepts that have motivated the studies undertaken for this thesis.

## The scope and quality of the archaeological record

sses have produced them. The degree to which this occurs therefore impacts the hope we have of ever choosing between competing explanations, and is for archaeology especially pertinent as we deal with fragmented empirical record fraught with various systematic and un-systematic biases that impact the quality of our data.    

The quality of the data available to us is consequently fundamental for knowing what questions we can and cannot hope to answer about the past. Lower quality data will lead to averaging and smoothing, where for example a reduced temporal resolution can lead to chronological smearing that hides smaller scale oscillations and variability [@bailey2007]. The same principle extends to the spatial scale, where a lower empirical coverage means that answers to questions pertaining to processes operating at the scale of individuals, sites or smaller regions might not be empirically tractable, and a larger view might be necessary to achieve the empirical coverage necessary to bring into view the processes of interest. Furthermore, this issue also pertains to what @perreault2019 terms the dimensionality of the data, Loss will here result in a reduction of variability and richness, for example in the composition of artefact assemblages. 

Furthermore, loss and mixing can be more subtle effects than complete absence of data, which can potentially be more easily recognised and thereby accounted for. Moreover, effects such as loss, mixing of past events and analytical lumping will most likely not impact the quality of the data in a uniform way. Taphonomic loss is likely to be more severe the further back in time one moves [@surovell2009a], and analytical bias following from disciplinary interests or what geographical areas have been subjected to archaeological investigation will also skew our impression of the past [@binford1964]. Mapping the spatial and temporal quality of the archaeological record is thus critical for knowing what past processes we would be able to discern, and by extension what kind of archaeology we can hope to do.

A central aim of this thesis is to contribute to mapping the data available to us. While there can be merit to accumulating large amounts of data, as this can average out idiosyncratic and random variation or erroneous data points, more data will not, by itself, [@huggett2020]. Discussing this in the context of \'Big Data\' in archaeology, @huggett2020 states that  \'digital data not only offer possibilities but may also constrain actions, they limit as well as enable, and this may not always be recognized in the thrill of the revolutionary discourses surrounding Big Data and the lack of a proper data gaze.\' While seeing data as given, free of influence from our preconceptions have long been critisised in archaeology, several authors have expressed concerns with the degree to which developments in digital technology may lead to an over-enthusiasm that neglects the the messy, fragmentary and complex nature of archaeological data, and that this can lead to fetishisation of digital data following from its availability, tractability and often elegant results [@huggett2020]. 

While large amounts of data do not offer a way to side-step the fundamental issues with archaeological evidence, there is nonetheless decidedly value to evaluating data at multiple scales. Not only can this reveal patterns and processes that operate at some scales and not at others, but different scales of perspective can also feed back to each other and reveal biases or inconsistencies. A central issue with digital data is therefore transparency with regards to its creation, manipulation, handling and finally with how it is cast as evidence. This will allow ourselves and others to assess how these steps might influence the arguments that are made. How this is attempted to be tackled in this context will be laid out in more detail in the next chapter.

## Chronology, archaeological cultures and modifiable analytical units

The study area of this thesis, as situated firmly within south-eastern Norway, is for the most part believed to have followed the same unified trajectory in terms of overall cultural-historical developments and expressions of material culture through the Mesolithic. At least within the analytical detection limit that has characterised the field thus far. What has been of greater concern is the temporal transition between the occurrence of cultural taxonomic elements within the region. In Norwegian Mesolithic research more widely, however, the question of both regional variation in material culture and its timing has led to discussions of whether a concept known as \'chronozones\' has any merit as a framework for systematising the archaeological material. While this is a concept that has remained marginal in archaeology as a whole, as it is mainly used by some practitioners in Norwegian Mesolithic archaeology [e.g. @bjerck2008; @nyland2016; @fretheim2017; @breivik2018; @skar2018], it is related to fundamental issues faced within archaeology in general.

The concept originates in a paper by @bjerck1986, in which he attempts to tackle the distinction between the archaeologically defined cultures of Fosna and N√∏stvet in the context of Western Norway. Instead of an ever-continued nuancing of these terms as more variation and idiosyncrasies are encountered in the archaeological record, @bjerck1986[117--119] instead suggests a division of the Mesolithic period into a series of time-intervals denoted chronozones, originally at a resolution of 500 years, which he argues could facilitate a Pan-Scandinavian framework for approaching the Mesolithic [@bjerck2008, 72--73]. The concept of chronozones is taken from the geosciences, where the term is used to denote stratigraphic layers that formed over the same specific time-span on a regional or world-wide scale, known from geochronological units such as for example the Preboreal, Boreal and Atlantic time-intervals [e.g. @salvador1994, 83--85]. Bjerck's motivation for adapting this to archaeology is to form a framework that is neutral with respect to cultural variation across space and time. He argues that traditional archaeological units of analysis, typically denoted by terms such as cultures or techno-complexes that are discretely delineated in time and space, has led to an artificial partitioning of the archaeological material that is less open to gradual temporal change and spatial variation -- an issue that has been contended with by many archaeologists through the years [e.g. @childe1956, 121--125; @butzer1982, 279--320; @smith1992; @clark2009; @roberts2011; @reynolds2017]. Bjerck argues that the use of neutral 500-year time-intervals will reduce the degree to which analyses will overemphasise homogeneity within, and exaggerate differences between such analytical units. To further illustrate the issues Bjerck attempted to tackle, it is useful with a detour via the concepts of the Modifiable Areal Unit Problem (MAUP), as taken from the field of geography [e.g. @harris2006], and its recently coined temporal equivalent, the Modifiable Temporal Unit Problem [MTUP, @bevan2021].

### The MAUP and MTUP

The scale problem, as its often called, is central to geographical research. This follows from the chosen scale for the necessary generalisation of continuous phenomena, it's dependency on the density of sampling points for this data, and the variable spatial scales that different phenomena operate across [@harvey1968]. Some central implications @haggett1965 identifies in relation to this is the *scale-coverage problem* which is related to the variable areal coverage between studies, the *scale-linkage problem*; the problem of comparing results captured at one spatial scale with those captured at another, and the *scale-standardisation problem*; the issue of how to adjust data that have been captured on varying spatial scales [@harris2006, 46]. Extending on the last problem, @haggett1965 shows how adjusting the boundaries used to delineate the originally retrieved data can have substantial impacts on any basic comparisons of occurrence of phenomena, which is the issue that underlies the MAUP.   

The MAUP is defined by @heywood2002[8] as \'a problem arising from the imposition of artificial units of spatial reporting on continuous geographical phenomenon resulting in the generation of artificial spatial patterns\' and is an issue that underlies most if not all analyses that draw on areal data [@harris2006, 48]. A typical example from archaeology is the areal unit of the site, the delineation of which typically follows some notion of concentration of artefacts. However, the density of artefacts over a landscape can be conceived of a continuous phenomena, and so it's definition will always be modifiable and subject to choice, whether it follows from some kind of statistical procedure or a more intuitive definition. The same problem extends to the smaller scale, such as with the definition of site features based on the concentration of charcoal, and up in scale, such as to the definition of archaeological cultural areas. How these units are defined will impact the most basic comparison between them. Given the arbitrariness and potential variation that might exists in the aggregation procedures underlying our areal units, it is therefore always a danger that discovered patterns could simply be artefacts of the aggregation technique.     

These issues can also be extended to the temporal scale, with @bevan2021 recently having given a demonstration of how archaeological periodisation involving lumping and splitting of phenomena within disjoint time-intervals have analytical consequences that remain under-appreciated within archaeology. First, employing strict cut-offs between temporal units -- units that often also vary in their duration -- has major implications for comparison between these units, and can, as @bjerck2008[73] also notes, lead to an artificial and inadvertent overemphasis of the transition between these. Basic operations such as comparing counts will be skewed by variable duration of these units, and the position of breaks between them can be highly influential to the appearance of the frequency distribution of events over time.

Building on @crema2020, @bevan2021 further define three types of uncertainty associated with this archaeological practice. The first is *phase-assignment uncertainty* -- how certain can we be that a given phenomena can be ascribed to a given phase. The degree to which this varies between different material categories means that it can be difficult to compare their frequency across archaeological phases. As was found in the third paper for this thesis [@roalkvam2022], the occurrence of formal tool types at the Mesolithic sites in the study appears to be greater further back in time. This as opposed to younger sites, which are to a larger extent dominated by generic debitage that can be more difficult to assign to a phase. This can have implications for how many sites are ascribed earlier periods, and, by extension, could impact a comparison between phases. The second pertains to the *within-phase uncertainty*, the degree to which the occurrence of a various phenomena have an equal likelihood of occurrence throughout an archaeological phase. For example, in typological discussions for the Norwegian Mesolithic, the occurrence of different artefacts types is in practice typically treated as having a uniform occurrence within a given time-span.  The final dimensions @bevan2021 highlight is the *phase boundary uncertainty*, which pertains to the start and end points of the archaeological phases themselves. As these are typically defined by a complex interplay of multiple cultural phenomena, they are seldom meant to operate on the scale of individual years, but will in practice often be operationalised as such. 

### Archaeological chronozones

While possible methodological ways around these issues are presented in the works cited above, neither the MAUP nor the MTUP have any clear solutions, and the magnitude of their impact will depend on the given research question and accompanying analytical scale. However, their formulation arguably form a better frame for understanding these issues than the concept of chronozones. I believe chronozones can instead obfuscate the distinction between the temporal and the spatial scale, and that it can lead to a conflation of typology -- understood in its widest possible sense -- as a methodology for systematising archaeological material and its potential use as a dating method. As @bjerck1987 states, typology obviously has its place as a culturally responsive framework in both time and space. Chronozones, on the other hand, are supposed to make comparisons across typologically inferred boundaries in space and time tractable. 

In her comment to Bjerck's paper, @skar1987[35] notes that geological chronozones couple pan-regional stratigraphic layers with the calendar scale, but that there is no equivalent pan-regional archaeological phenomena that equally consistently correspond to a section of the calendar scale. As @bjerck1987[40] further underscores in his response, archaeological chronozones are therefore not, unlike typological frameworks, meant to be culturally responsive, but are to represent a neutral temporal scale, typically instantiated as 500-year intervals. However, as @√∏stmo1987 and @mikkelsen1987 note in their comments to Bjerck's original paper, this purpose is already fulfilled by the calendar. If the stratigraphic information related to a specific time-interval is removed from the geological chronozone, only \'chrono\' remains. Similarly, if the archaeological chronozone is not meant to hold any culturally responsive component, only the time-scale remains. 

As a culturally independent scale, the calendar scale will always be preferable to the that of chronozones. Not only because it is firmly established, but also because it already allows for more variation in the temporal resolution associated with different phenomena to be systematised, and allows for their duration and uncertainty of occurrence to span a wider range of aggregative time-units [cf. @reitan2022, 187]. The ability to shift and readjust the temporal resolution depending on the phenomena one is attempting to align and contrast is important as ‚Äòdifferent timescales bring into focus different sorts of processes, requiring different concepts and different sorts of explanatory variables‚Äô [@bailey1987, 7; @bailey2007].

In replying to this critique, @bjerck1987[40] states that questioning the need of chronozones when we already have the calendar is like asking \'Do we need the term "month" when we have numbered days?\'. This would seem to imply that chronozones, like the month, is to be of a predefined duration, at least within any individual study, and that variable duration and temporal uncertainty of phenomena to be analysed has to be collapsed into these aggregative units. Another question is also if the terminology used with chronozones is better than simply stating what time-intervals we are dealing with. For example, @bjerck2008 uses the term Middle Mesolithic (MM) to denote the three chronozones MM1, 8000--7500 BCE; MM2, 7500--7000 BCE; and MM3, 7000--6500 BCE. A reader coming across \'MM3\' instead of \'7000-6500 BCE\' therefore has to keep in mind that this simply refers to this specific time-interval. The term Middle Mesolithic should be entirely disregarded, as it is in this use meant to be devoid of any cultural meaning. One could perhaps change terminology to something that doesn't have as many cultural and research historical connotations as the Middle Mesolithic, but it strikes me as altogether unnecessary to do this via the chronozone, as this is simply solved by establishing a reference frame only using the calendar scale in the first place. If one wants to use a time-scale of 500-year intervals it would in my mind be better to simply define this independently of the now inflated discussion of chronozones, not least because I believe the discussions of the concept demonstrates that its use can lead to unnecessary confusion -- if not for practitioners, then likely for readers.

In their comments to the original paper by @bjerck1986, @√∏stmo1987 and @mikkelsen1987 deem chronozones an unnecessary and complicating concept. Commenting on these critiques, @nyland2016[53--56] states that both of the authors make their comments in light of typological frameworks for Mesolithic south-eastern Norway, but that neither address the issue of the geographical coverage that these have. However, this is first and foremost an empirical issue rather than something to be solved by new terminology, and clearly not by the chronozone, which is a concept meant to be culturally unresponsive. 

Drawing on an example given by @nyland2016[55]; if the question is if central Norway falls within the same cultural sphere as south-eastern Norway, understood to be determined by comparable material culture, then this is dependent on two dimensions, assuming the problem of the initial delineation of these two regions has been resolved. The first is an evaluation of the degree to which characteristics of archaeological material in the two regions is considered to be similar, according some criteria. The second pertains to the timing of the occurrence of this material. To establish this necessarily demands temporal data that is independent of the typological framework itself, or possibly by reference to some principle of seriation with the uncertainty that this entails [e.g. @dunnell1970]. If a set of artefact types occurs in both central Norway and south-eastern Norway, this could lead one to suggest that a similar kind of cultural expression is common to the two regions. If independent temporal data associated with this material, such as radiocarbon dates, additionally indicates that there is a temporal synchroneity between their occurrence, then this would lead one to conclude that this cultural expression appears to occur simultaneously -- within some level of temporal certainty. Depending on the magnitude of artefactual and temporal evidence for this coincidence, this could then lead one to apply this typological framework as a dating method in the case that one excavates a site in either region and discover material of the type in question. A continuous adjustment and evaluation of the reliability of the identified cultural affinity and the derived typological dating frame will of course be necessary, but will have to be founded on material culture and the position of their occurrence on the calendar scale. This also pertains to the co-occurrence of various archaeological evidence and their wider cultural implications, for example whether or not some artefact type tends to be associated with agricultural activity. If either region lack artefactual or temporal data, then either the nature or the timing of cultural affinity cannot be resolved. The concept of chronozones cannot overcome these issues, and, I think, is more likely to confuse them. 

In conclusion, I therefore agree with @√∏stmo1987 and @mikkelsen1987 in that the concept of chronozones represents an unnecessary complication. Although some of these complications follow from misunderstandings of the original proposition [as pointed out by @bjerck1987, 40; @nyland2016, 55], it nonetheless appears to sometimes lead to the muddling of several spatial, temporal and culturally taxonomic issues. These are therefore arguably best handled by reference to already well-established terminology, and by the use of modern methods that allows for the formal definition and handling of fuzzy and uncertain categorisation in the aggregation of data, both on the scale of material culture, time and space [e.g. @bayliss2007; @crema2012; @fusco2020; @bevan2021; @shennan2015].

The amount of ink now spent discussing chronozones also means that invoking archaeological chronozones carries with it the necessity to clarify how one intends to use it, which can be circumvented by avoiding the term altogether. Furthermore, as a term suggested for use in Pan-Scandinavian Mesolithic research, I believe this idiosyncratic terminology will also unnecessarily divorce the field from discussions of the same issues within archaeology more widely, while also making the field less accessible to outsiders, more difficult to couple with adjacent disciplines, and possibly lead to confusion with the geological chronozone. It is therefore unclear what the concept now provides beyond what well-established archaeological and colloquial terminology already covers, perhaps apart from making us aware of these universal archaeological issues.  

### Radiometric and archaeological dating methods

Rather than being based on predefined discrete time-intervals beyond the calendar scale, the analyses undertaken in the papers for this thesis largely rely on absolute dates from radiocarbon- and shoreline dating. These two methods can be denoted radiometric and archaeological dating methods, where the first category is based on a process of radioactive decay and the second is based on some regularity in human behaviour leading to predictable variation over time. In the case of shoreline dating, this follows from the proclivity of people to have continuously settled close to the shoreline throughout the Norwegian Mesolithic, where the coupling of this with the calendar scale follows from the timing of shifts in the relative sea-level. However, a note should also be made on the fact that radiometric dating is never purely based on a steady process of radioactive decay. Apart from interpretations to do with the calibration, reliability and sampling context of for example a ^14^C-date, this also has to be seen in light of other chronological information and the wider archaeological context [@wylie2017]. As with the process of shoreline displacement, the cessation of radiocarbon uptake in an organism also requires an interpretative step to be meaningfully associated with a cultural event of archaeological interest. 

It is important to underscore that given the scarcity of radiocarbon dates, and the relative low resolution of shoreline dates, typological frameworks responsive to variation in material culture can most decidedly offer valuable chronological insights, even though this is not directly integrated in the studies undertaken for this thesis. Furthermore, while the analyses are done here using dating methods that largely operate irrespective of archaeological periodisation, the results are frequently narratively and informally associated with general cultural developments believed to characterise the Stone Age of south-eastern Norway, as roughly outlined in Chapter 2. This is predominately done in an approximate manner with reference to what are best viewed as temporally and spatially fuzzy frameworks, and is based on the underlying logic that frequent co-occurrence of a range of material expressions in time and space, as suggested by others, reflects some level of meaningful cultural cohesion. This also means that the term culture is used in a loose archaeological sense and is not presumed to equate to a people or a unified unit in terms of language, genetics, or social structures [see e.g. @roberts2011 for a thorough discussion of the culture term as used in archaeology]. While it appears reasonable to assume that such cohesion has largely resulted from the same cultural factors within the geographically limited area of south-eastern Norway through the Mesolithic, it is also worth noting that empirical correspondence can be driven by other factors. This includes cases where people have arrived at the same technology in disjoint regions of time and space, known as convergence, as well as cases where the same technological expression has occurred across a range of different cultural and environmental settings [which for example has been argued to be the case with slotted bone tool technology in Northern Europe, @manninen2021] -- effectively an example of equifinality.

## Hunter-fisher-gatherers

Hunter-gatherers or foragers are useful but fuzzy and not unproblematic synonyms that are typically, but not exclusively, used to denote societies that have a diet based on non-agricultural produce [@kelly2013]. One implication of this defining characteristic appears to be a case where environmental variation represents a considerable constraining back-drop against which cultural variation can occur. As these dimension can have a fundamental impact on the economic basis of these societies, environmental variability has been frequently shown to impact central aspects of forager societies, such as population dynamics and mobility patterns, which in turn are interrelated with virtually all dimensions of these societies [e.g. @kelly2013; @morgan2009; @bird2008; @hoebe2023; @ordonez2022].

However, while it appears to be the case that variables such as temperature and precipitation dictate general variability among prehistoric and historic hunter-gatherers, this has to be severely qualified. First of all, while this appears to be the case *in general*, it can hardly be assumed to apply to any individual case [@johnson2014]. Secondly, understanding precisely what consequences variation in any single environmental variable has in any given case, if any, will be severely complicated by both the societal and environmental systemic wholes that respond to this variation, with some systems being more or less robust to such perturbations, depending also on the time-scale over which it operates and can be recognised archaeologically. While for example drought could intuitively be taken to represent a societal challenge, this certainly need not be the case. Drought might very well present more opportunities for resource exploitation than it eliminates [@arponen2019, 5--6 with further references], illustrating the point that any systemic variation, environmental or societal, can represent both threat and opportunity to systemic wholes, and simultaneously represent threat and opportunity to different parts of the system. 

What role environmental variability has for hunter-gatherer societies is also likely to be impacted by research-historical trends and. This is 

The further delineation of this thesis to focus on coastal societies has some further implications for what ethnographic data can be reasonably drawn on, and some of the implications this can be expected to have for the structure of the societies in questions. First of all, the exploitation of marine resources is found to, in general, have been associated with a higher net productivity. The term \'fishers\' is included the header for this section to underscore this coastal setting and underline the likely role fish played for these societies. However, while marine resources can reasonably be assumed to have made up a large of the diet of these societies, this  likely to a varying degree involved the catching of fish. The term hunter-fisher-gatherer is therefore taken by many to  [e.g. @bergsvik2009b; @mansrud2018]

As representing a considerable stage in the human adaptation to diverse environments, marine habitats are deemed an essential component in the evolution of modern humans and determining for the spread of the species across the globe. In Palaeolithic archaeology, the coast has traditionally been seen as a hostile environment for early hominins -- a challenge to be overcome. Marine habitats and resource-use has also been characterised as a central for the evolution and 

A note should be made on the fact that in the literature the terms *coastal adaptation* and *coastal resource use* are sometimes taken to imply different and quite specific things [see e.g. @faulkner2021; @marean2014; @will2019]. Coastal resource use is in this understanding seen as something that is conducted sporadically or occasionally, and that has limited transformative feedback effects on the life-ways of the societies in question. Conversely, coastal adaptation involves a degree of coastal engagement and commitment that has an altering effect on these societies. I do not use the terms in this manner here. The conceptual distinction is certainly an important one, especially as marine exploitation is believed to potentially, but not necessarily [e.g. @erlandson2001], lead to technological ratcheting and increased societal complexity. However, these quite specific connotations of the terms stand in danger of leading to misunderstandings for readers that have another understanding of adaptation, which need not be defined by some threshold in the intensity of coastal engagement. One response to the specifics of a given marine habitat might for example be movement and extended use of terrestrial resources, which would fall within a more inclusive definition of adaptation to a given coastal environment. While the above division might have merit in some analytical settings, the dependence on marine resources is arguably better understood along a continuum that I believe this distinction might unnecessarily dichotomise. 

Further underlying issues with employing the hunter-gatherer society as a heuristic category with which to approach the material are ways in which the history of research into such societies might dictate . For example, a socio-evolutionary perspective was a fundamental influence at the inception of the research into hunter-gatherers. While such views are deemed a grossly inappropriate reference frame today, it can be difficult to fully grasp and account for ways in which this influences the fundamental categories we operate with, however divorced they may appear. Related concerns have also been voiced in Norwegian Mesolithic research, where for example @√•stveit2014 is vary that a view of EM societies as highly mobile and LM societies as more sedentary might, at least in part, follow from an implicit view of prehistory as a continuous trajectory towards increased societal complexity. This implicit view might have forced us to cast the material traces available to us in  Calls for more directed attempts at unveiling how such research-historical conditions might influence how we conduct Mesolithic research have recently been voiced [@elliott2022; @elliott2023], and questions such as . 

While it is beyond the scope of this thesis to contribute much in the way of bringing these influences and their consequences to light, the next chapter will outline a framework that is employed in an attempt to clarify the evidential logic that underlies the undertaken studies. Hopefully, this can contribute to making evident where such biases might have influenced analytical choices and the drawn conclusions. 

\'sticking to the data\' [@longino1999, 218] is not an, but rather that conceiving of archaeological research as a social undertaking by entire research communities has implications for how this is best done, and can be drawn on to facilitate feedback from and 

## Palaeodemography
Palaeodemography or the study of temporal and spatial variation in the size and structure of past populations is a fundamental problem for archaeology [e.g. @shennan2000; @kintigh2014; @french2021]. This follows from the fact that demography is a determining factor in processes such as genetic diversification, social network structure and scaling, technological innovation and accumulation, as well as. As human culture is in large part determined by human interaction, 

One Known as the forager paradox. [@french2021, 4]
One of the implications of these findings is that the interpretation of archaeological proxies for population size is not as straightforward as one might immediately think. This in turn, needs to be kept in mind both when devising and comparing multiple population proxies, and in the construction of the narrative that builds on any numerical results.

Demographic modelling in early Holocene Fennoscandia has taken on a few different. In most recent years this is the SPD approach [@solheim2018; @solheim2020; @nielsen20; @jorgensen2020]. The SPD approach is based on summing the probability distribution associated with ^14^C-dates. However, there are a series of methodological and conceptual issues with this procedure, some of which have been dealt with and others which are integrated into the methodology and needs to be accounted for when interpreting any results.  

Preconceived notions of what has characterised hunter-fisher-gatherer societies will at some level necessarily impact how the material under study is interrogated. This follows both from what research questions are deemed central, and because these notions will have impacted how the material has been retrieved and recorded. These notions are therefore to some degree inescapable influences on any research into the Norwegian Mesolithic. However, in the next chapter I will argue how this does not, and should not, lead to epistemic despair.

<!--chapter:end:03-analytical.Rmd-->

# Model-based archaeology

Over the years, several works have purported the benefits of a model-based archaeology [e.g. @clarke1972; @wylie2002, 91--96], which has especially gained a footing within the sub-field of computational archaeology [e.g. @kohler2007; @lake2015; @barton2013; @gonzalez-perez2018; @romanowska2015; @brughmans2021]. The goal of the next two chapters is two-fold. First to elucidate what defines or can define a model-based scientific approach, and in the next chapter to demonstrate how this can form a useful framework for archaeological inquiry by drawing on examples from the papers of this thesis.

Central to the present chapter are four problem areas in the understanding scientific models, as identified by @frigg2018: 1) The ontological: what are models? 2) The semantic: what do models represent? 3) The epistemological: how do we learn with models? And 4) what consequences do the use of models have for overarching principles such as scientific realism, reductionism and explanation?

One fairly common understanding of models simply entail seeing them as a set of simplifications or assumptions concerning real-world phenomena [e.g. @barton2013, 154]. Any representation could thus be considered a model whether it is generated physically, digitally, verbally, simply imagined, or is construed in a natural or formal language. Scholars arguing the case for model-based archaeology often start out by making the point that whether we acknowledge it or not, we always employ such abstractions when attempting to understand past reality [@kohler2007, 4; @lake2015, 7]. The infinite complexity of reality means that any description of it has to be a simplification, and even if we were able to, a complete rendition of reality would not be a worthwhile endeavour in its own right. A perfect reconstruction of reality would be a tautology, which without perspective offers neither insight nor understanding [@yarrow2006, 77; @slingerland2012, 14--19]. Put differently, whether we understand archaeology as tasked with providing explanation, understanding, or interesting narratives about the past, any demand for a higher empirical resolution, for its own sake, would be a refutation of theory [see @healy2017].

These are, however, universal scientific points, variations of which have been made under diverse headings of archaeological theory [e.g. @johnson2010, 7], and which extends far beyond the scientific endeavour, captured by what the artist Derek Jarman [-@jarman2000, 320, see Figure \@ref(fig:jarman)] described as the \'intellectual imperative of abstraction\'. It would thus follow that if the term model is taken to denote all generalisations or abstractions of reality, which in its ubiquity would include any description or explanation, it is not given why this would have to be dealt with within a comprehensive model-based archaeology. The arguments in favour of a distinct model-based archaeology tend to follow from *how* this necessary simplification should be embraced, and in turn handled. What this entails can be foreshadowed here by invoking the classic quote from @box1979 [2]: 'All models are wrong but some are useful'. But if all models are wrong, what is their epistemic value? To begin to answer this question, the above view of models, simply seeing them as abstractions, will be accepted for now without regard for their demarcation to data, theory and hypotheses.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{figures/jarman} 

}

\caption{Derek Jarman, \textit{Untitled (Yellow Painting - Archeologies)}, 1983. Oil on canvas, 134.6 x 101.6 cm.}(\#fig:jarman)
\end{figure}

## Confronting beliefs with data

Smith [-@smith2015; @smith2017] has stated that one of the most central questions we can ask about our archaeological arguments is 'How would you know if you are wrong?'. Archaeological explanation often take the form of what @binford1981 termed a *post hoc* accommodative argument. This involves first gathering and categorising the data of interest, often using variables chosen by convention and convenience, and then building an explanation around any discerned patterns [@clark2009, 29]. This data-dredging or pattern-searching approach is argued to constitute a limited inferential framework for a couple of reasons.

First, what among the virtually infinite aspects of the material available to us is considered interesting will always be determined by our beliefs concerning the processes that have resulted in their manifestation. What characteristics of the material is recorded and drawn on to organise it will dictate what patterns one can hope to reveal. As @popper1989 [46] framed it, without an underlying theory, how would we know what to look for? If one follows what has been done conventionally, without taking any explicit stance towards this, one will be dependent on how others have conceived of what questions are of interest and how these can be answered. Furthermore, this accommodative process can never falsify our argument, and @smith2015[19] likens it with 'the farmer who paints bulls-eyes around the bullet holes in his barn in order to show his superior shooting skills.' *Post hoc* accommodative arguments can provide the identification of empirical patterns with respects to the employed units of analysis, which in turn can form the basis for social and behavioural hypotheses. But @binford1981 [85] has argued that such arguments can at best be 'treated as provocative ideas in need of evaluation'. @clark2009 [29] states that a necessary next step is to derive empirical implications of this hypothesis, which can be evaluated against a part of the archaeological record that is independent from the material originally used to derive it [also @barton2013]. Subsequent testing thereby provides an opportunity to reveal if one's accommodative belief is wrong.

The explicit testing of archaeological explanations was assertively introduced to the discipline with processualism, which argued that archaeology should adopt the explanatory goals of positivist social sciences. How this was to be done first follows from the standard processual view on what the archaeological material represents. Here, material culture was seen as an integrated part of -- and the result of -- total, multidimensional cultural systems [e.g. @binford1962]. As such, theories concerning how all aspects of cultural systems would influence and manifest in the material record should be conceived. Central to this is that the archaeological material represents an objective, albeit complex empirical record that reflects empirical causes, irrespective of our beliefs about what these causes are. The empirical material will in this processual understanding therefore offer a direct link back to this systemic whole. Archaeological material is representative of the multidimensional causal chain from cultural system to the archaeological record. The goal was therefore to develop theories concerning the prehistoric systemic whole and what processes have influenced the remnants available to us, which were then to be tested by drawing on the hypothetico-deductive approach. Furthermore, drawing on the deductive-nomological or covering-law framework, as taken from the logical positivist/empiricist view of Hempel [e.g. -@hempel1965], the ultimate goal was to establish laws pertaining to the conjunct occurrence of certain types of material remains with certain types of societal systems, irrespective of time and place.

It should be noted here that the programme of logical positivism, and the more mature logical empiricism [although see @uebel2013 on this distinction], were far more nuanced that what they are often given credit for in the archaeological literature concerned with establishing why these views were misguided [@gibbon1989, 8--60]. This is equally true for the over-simplified presentation that is given here. However, this can in part be justified with reference to the naive versions of these programmes that were adopted by positivist social science and archaeology at the time [@gibbon1989, 91--117].

According to @hempel1965 [231--243], the goal of science is to establish laws that are deductively valid, of the kind given by the classic example *All men are mortal / Socrates is a man / Therefore, Socrates is mortal*. If the premises are true, then the conclusion will always be true. However, when adapted to archaeology, the proposed laws were so banal that @flannery1973 stated that attempts at adopting Hempelian empiricism 'has produced some of the worst archaeology on record'. The search for covering laws was therefore quickly abandoned by most practitioners. Furthermore, whether an argument is deductively valid or not is not dependent on whether the premises are true. If it happens to be true that all men are mortal and Socrates is a man, then the deductively valid argument is said to be sound. Determining whether the premises are true of the world depends on non-deductive reasoning. A deductively derived test that successfully corresponds with data only supports the hypothesis inductively, a point that appears to be lost on early processualists [@chapman2016, 27]. However, giving up on the search for covering laws and deductive certainty need not entail that hypothetico-deductive testing is misguided, and more modest goals of confronting beliefs pertaining to specific contexts or research questions with data is, I will argue, still very much a viable goal.

### Confirmation

Within a classic hypothetico-deductive system, an initial goal is to derive as many empirical implications of an explanation as possible. These implications are then to be tested by comparing these implications to actual observed data. Drawing on Carnap's [-@carnap1936, 425] 'gradually increasing confirmation', this entails that each time a model matches the data, the confidence that the model is true is increased. If, on the other hand, the model fails, it can be discarded as untrue. This should thus lead to the continual rejection of false models, and move us ever closer to, but not necessarily to, the actual model of reality. Although certainly an enticing prospect, there are problems related to this approach, irrespective of any goals of establishing covering laws.

A fundamental issue for hypothetico-deductivism, and scientific inference as a whole, follows from Hume's problem of induction [e.g. @ladyman2002, 31--61]. As an empiricist, all knowledge about the world was for Hume derived from sensory perception. Any reasoning that extend beyond observation, past or present, is based on cause and effect. However, since we can never observe a causal connection between events, the conjoined occurrence of observations is all we have to draw on. As there is no logical necessity for regularity in patterns to hold beyond what we can observe, there is no logical foundation for inductive reasoning -- there is no logical connection between the observable and unobservable. While we might observe the sun rise every day, there is no logical contradiction in believing it will not rise tomorrow. Hume held that while inductive reasoning will continue to be fundamental to science, and our every-day lives, it therefore has no logical justification. Following from the problem of induction, an issue for hypothetico-deductivism therefore pertains to the value of testing an hypothesis, and whether with successful tests our belief in the hypothesis should increase.

The logical empiricist attempts at working around the problem of induction and establishing a logical justification for confirmation was never successful, and a move to stating our beliefs in probabilistic terms never dissolved this fundamental issue. Central here is what is known as the paradoxes of confirmation [e.g. @sprenger2023], of which Hempel's [-@hempel1965, 12--20] own raven paradox is a classic example [see  @goodman1983, 59--83 for the so-called new problem of induction]. If the hypothesis is that all ravens are black, this is logically equivalent to the statement that if something is not black it is not a raven. If we were to observe a black raven, this is evidence in support of the hypothesis. The paradox follows from the second statement: Given their logical equivalence, the observation of a green apple would be evidence in support of the hypothesis. Paradoxically then, we can study ravens by looking at apples. While problems of confirmation such as this are simple, they have proven difficult to resolve and a logically sound justification for confirmation is yet to be agreed upon [e.g. @godfrey-smith2003, 39--56].

### Falsification

One of the most influential contentions with the issue of testing is found with Popper and his concept of falsificationism. Popper, also a sceptic of induction, held that the problems of induction cannot be resolved. However, this is not of concern, as science in fact progresses not with confirmation but with falsification. In an attempt at demarcating science from non-science, Popper [e.g. -@popper1989, 33--66] stated that a theory can only be considered scientific if it has the potential to be refuted by observation. A theory that is compatible with all empirical variation is unscientific. The test of an hypothesis should be aimed at falsifying it, not confirming it, and an hypothesis that is not proven false should simply be subjected to even more stringent and elaborate tests. It is with each new rejection of an hypothesis that science progresses and we learn something about the world. Although it will inevitably be falsified, a good theory for Popper is therefore one that is bold, risky and corresponds with the world in surprising ways. There are, however, further issues related to the fundamental prospect of confronting our beliefs with data.

As insight from complex systems theory demonstrates, sensitivity to initial conditions can lead both different causes to produce similar empirical results, and similar causes to produce different empirical results [@vanderleeuw2004, 121; @premo2010]. This reflects the problems of equifinality and underdetermination, as presented in the last chapter, where several explanations can agree on the empirical data, but disagree on the underlying causal mechanisms. This follows from the ubiquity of measuring error and the sensitivity of complex systems to minute variation. One classic example in this regard is the complex system of the weather, which can only be reliably predicted a few days into the future. Human systems are far more complex than that of the weather. Consequently, this renders the prospects of empirical confirmation or falsifiability weakened, and preference among different, even contradictory explanations can often not hope to be based on observable data. In the case of archaeology, explanatory models are additionally faced with our generalisations of an already sparse and fragmented archaeological record, further increasing the likelihood that several explanations account equally well and are underdetermined by the data at hand. However, underdetermination and sensitivity to initial conditions can also impact the assumptions underlying an explanation. To show how this is an issue we can draw on what is known as the Duhem problem [after @duhem1914], or the Duhem-Quine thesis [drawing on @quine1953, and the holistic theory of testing; @psillos1999, 164], which states that nothing is necessarily learned from rejecting an hypothesis on the grounds of a test.

Drawing on @hvidsten2014 [184--187], we may postulate a simple model holding that mechanism A, under assumption B, implies C. In a test in which A occurs, it would in a hypothetico-deductive understanding increase our belief in the model if we could then reliably measure that C is true. In the case of Popper, the model is simply yet to be falsified. If, on the other hand, C is not true, this would imply that either A or B are untrue. We would not, however, be able to derive logically which of A and B are untrue. This would perhaps not appear to be an immediate reason for concern. As long as one aspect of the model is untrue, the model is untrue, and should be rejected. The problem is that we know that models always contain a multitude of untrue assumptions. Drawing on the classic quote from Box above and the earlier discussion on abstraction, all models involve subsuming the virtual infinite complexity of reality and thus cannot work without an equal amount of untrue assumptions that could impact a test [a point made in the context of archaeology by @salmon1975].

In exemplifying the Duhem problem, @ladyman2002 [77--78] gives the example of testing Newtonian gravitational theory by observing the travel of a comet. The theory of gravity alone does not provide a prediction for this path. It also depends on factors such as the mass of the comet, the mass of other objects in the solar system, and their relative positions, velocities and initial positions, as well as Newton's other laws of motion. If the test was to fail, this failure can follow from an untrue hypothesis, but also from a misspecification of an assumption that is subsumed in the test -- such as background conditions, measurement error, and initial conditions of the system. The Duhem-Quine thesis holds that any theory can be saved from refutation by adjusting it's auxiliary assumptions [@psillos1999, 165]. At some level a decision of whether the explanation has in fact been interfaced with observation is therefore needed. As stated by @ladyman2002 [80], 'falsification is only possible in science if there is intersubjective agreement among scientists about what is being tested.' While a severely complicating issue for falsificationism, as Popper also recognised, his proposition still holds if it is qualified by stating that for a hypothesis to be scientific, it has to have the potential to be refuted by some kind of observation. The challenge is determining what kind of observations this is [@godfrey-smith2003, 66].

Drawing on this issue with testing and falsificationism, several authors have argued that these logical inferential schemas do not capture how science has actually progressed. This view can be related to naturalism, which can be conceived of as a perspective where science of philosophy should not be concerned with establishing universal, logically justified formalistic schema for how science should be conducted at remove from the scientific enterprise itself. In a naturalistic view, philosophy of science should rather draw on and be a continuation of scientific ideas themselves [@godfrey-smith2003, 149--162]. While formalistic logic can provide some important insights on what *can* constitute good components of strategies for scientific inquiry, such as aspects of Poppers falsificiationism, the scientific undertaking has been argued to be a far more messy enterprise, where attempts at establishing a universal logical inferential foundation is doomed to fail. As a practical example, the orbit of Mercury was not properly accounted for by Newtonian gravitational theory. While this was known for many years, it was not until Einstein's theory of gravity that this orbit was correctly predicted [@ladyman2002, 89]. Despite being unable to predict the orbit of Mercury, and thus being falsified, this did not cause the abandonment of Newton's theory of gravity.

Examples illustrating this point can be found in archaeology as well. For example, when new dates that dramatically push back the earliest human occupation in the Americas have been presented over the years [e.g. @holen2017; @parenti1991; @parenti2018], these have often been met with scepticism as related to their veracity, and geological and other non-anthropogenic alternative explanations have been proposed [e.g. @braje2017; @magnani2019; @agnolin2023]. How convincing an explanation is and what causes it to be abandoned thus clearly depends on more than data alone, not least because data is more than a simple binary category that is either observed/not observed. What data is accepted, what it is understood to represent, and if it is adequately confronted with a hypothesis is in part dependent on a decision by the person who observes and the wider research community. What we observe should to some degree dictate what we believe about the world. However, the examples above demonstrate that stringent empiricism is untenable and is not in fact how scientific insight is achieved.

## Instrumentalism and scientific realism

Arguments such as those presented above have in sum rendered suspect a uni-dimensional absolute demand for adherence with observable data, and presents a significant challenge to the prospect of testing our beliefs about the world. This realisation also underlies common understandings of the virtues of a model-based archaeology, in which a search for the true model of the world should be abandoned. Rather than assessing the correspondence between model and the world, the concern is rather with assessing the degree to which the mechanisms of concern correspond with the world [@kohler2007]. However, if we are to concede to the fact that all models are wrong, how can we ever trust model-based inference?

In a classical instrumental understanding, the goal of science should be the prediction of phenomena that matter [e.g. @hausman1998, 187--190], a view famously forwarded by @friedman1953. Whether prediction is achieved through the use of models that build on true causal mechanisms or not is irrelevant. As long as the predictions of the model has a satisfactory correspondence with the empirical variation of interest, it is deemed a success. This view is therefore compatible with the constraining realisation that all models are wrong, both because the truth of postulated causal mechanisms in and of itself does not matter, and because of the resulting relaxed demand for accordance with total empirical variation -- degree of empirical correspondence determines the choice between models.

Related views have also been advanced within archaeology. The most clear example can be found in the domain of archaeological \'predictive\' modelling, concerned with understanding where archaeological sites are located in the landscape [e.g. @verhagen2012]. These studies have sometimes focused on identifying where sites are located in the present-day landscape, irrespective of past motivations, so as to potentially reduce costs of land-development, or to help guide archaeological surveys in large areas where a complete coverage of the landscape is not possible. The concern then is knowing where sites are and are not located, not why.

However, one of the criticisms forwarded towards instrumentalism is that if the ultimate goal is manipulation of relevant variables for the improvement of society, this will depend on uncovering true causal mechanisms. While mere prediction depends on stable correlation, control necessitates causality [@hausman1998, 190]. As @elster2015 [18] puts it, explanation demands causation, and causation can never be revealed solely through prediction [see also @gibbon1989, 49]. One way to conceive of causality is as dependent on a counter-factual condition [e.g. @lewis1974; @morgan2015, 4--6], simply stated as A causes C if when A occurs then C occurs, and if A does not occur then neither does C. Instrumentalism and a focus on prediction and stable correlation can therefore never hope to explain social phenomena [see also @lake2015, 23--24]. Of course, causal explanation does not necessarily have to be the main concern for archaeology. One could argue that academic interest in causal explanation should not always be the guiding principle behind archaeological inquiry but rather, for example, that mitigating costs associated with land-development or assembling interesting and poetic, albeit more speculative narratives about the past can be more important goals. My view in this context, as stated in the introduction to the thesis, follows from a form of realist understanding, where scientific inquiry is as a strategy by which we try to confront theoretical constructs with empirical observation, aimed at aligning our beliefs as reliably as possible with what is true [@godfrey-smith2003, 161], where the ultimate aim is to answer why something we believe to be true has occurred.

Scientific realism has been the dominating perspective in philosophy of science for decades [@preston2013, 7], and so an enormous range of different realist positions exists [e.g. @psillos1999]. At its core, scientific realism is typically taken to entail the philosophical stance that there exist real observable and unobservable entities and properties, and that claims concerning the veracity of either dimension cannot be set apart [@psillos1999; @gibbon1989, 142--172; @wylie2002, 97--105]. The goal is to reveal these truths, where truth typically follows a commonsensical definition of being determined by what is the case, and not, for example, what we believe to be true or what is most beneficial [@ladyman2002, 157--158; see also @malnes2012, 19--30]. Regardless of whether or not it is possible to ever achieve, the goal of the realist is to reveal true, or approximately true [@psillos1999, 261--279], yet unobservable causal mechanisms that generate and shape the flux of observable phenomena. Scientific realism thus combines causal explanatory goals with ontological theses concerning the existence of observables and unobservables, and epistemological postulates on the possibility of gaining evidence for unobservables [@hausman1998, 191].

In a realist view, even the most careful empirical approach depends on theoretical assumptions that will determine what hypotheses are deemed relevant, what evidence empirical data are believed to represent, and how these are evaluated against hypotheses [@wylie2002, 100]. With the early post-processual critique of processualism, @hodder1984 argued that objective data is never tested against separate independent theories. These theories already underlie and determine how the archaeological material is recorded -- there is no theory-free data. To the realist, however, the realisation that we might view the world differently does not take away from the belief that we inhabit a common reality that exists and is true independently of what we think about it [@godfrey-smith2003, 174]. @shapin1985[355] stated that 'it is ourselves and not reality that is responsible for what we know.', echoed by the archaeologists @shanks1987[111] with the phrase \'there is literally nothing outside of theory\' as archaeologists simply \'create facts\'[@hodder1983, 6; cited by @wylie2015, 6]. This, however, is a false dichotomy. As human knowledge is a part of reality, not something outside of it, it is better to understand human knowledge as the result of both ourselves and the world [@godfrey-smith2003, 132]. By extension, and by drawing on @fodor1984, @godfrey-smith2003 [158--162] states that it is not enough to say that observation is theory-laden. The challenge is determining what theories influence observation, how they do so, and how reality manifests in observation.

As an extension of this view, the form of feminist empiricist perspective advocated by Longino [e.g. -@longino1990] through her 'contextual empiricism' follows from treating the social group as the foundational scientific unit. What constitutes a good explanation in a field of research is determined by the varying views and non-coercive consensus that is reached on these issues at the level of the research community. As we view the world differently, what ideas are brought to bear on an issue, and a decision of whether a theory has been adequately interfaced with data will thus follow from the diversity of that community. Ultimately, this thus extends on aspects of Mill's [-@mill1859] \'marketplace of ideas\' [e.g. @gordon1997] and Feyerabend's [-@feyerabend1970] \'proliferation of ideas\' as scientific virtues [@godfrey-smith2003, 114]. While there is a danger of simplistic generalisations of how for example sex differences influences how one views the world [@longino1990, 187--188], a healthy state for a research community would thus be one where a multiplicity of marginalised and privileged groups are represented. 

<!-- For @longino1990, this does not entail a retreat to relativism, but rather a pragmatic view on objectivity where claims are not [see also @chapman2016, 11]. -->

## What are models?

Building on the above, we can return to the issue of scientific models. While the classic hypothetico-deductive framework in a sense sees every model as a truth-candidate, they are for advocates of a model-based archaeology instead often understood as 'pieces of machinery that relate observations to theoretical ideas' [@clarke1972, 1]. A similar view can be found with Morrison and Morgan's [-@morrison1999] view of 'models as mediators', where a model is a concrete or explicit representation of observables and theoretical beliefs, and allows for a confrontation between these two dimensions. This is very much in line with the model as envisaged by @kohler2007, who sees them as constructions that have similarities with, but exist independently of the target systems that they are to represent. Models are constructions used to draw further inferences about the reality they are to represent, and are construed on the basis of what mechanisms we believe shaped the observables available to us. The hope is that when confronted with the world, the mechanisms of the model that the researcher is interested in correspond with those of the target system. This is how models have often been cast in a realist understanding, and variations on this are sometimes termed credible worlds, or idealised or isolating models (Gilbert 2008; Frigg & Hartmann 2018). These entail the inclusion of boundary conditions or assumptions considered essential for the model to function, the explicit or silent omission of aspects deemed unessential, and can involve an exaggeration of the characteristics of interest [@m√§ki2009].

To explicate the concept of models as mediators, it can be useful to think in terms of an epistemological hierarchy, extending from observations to high-level theory. In a Mertonian view [@merton1968], this extends from day-to-day working hypothesis of what data represents, to middle-range theories that act as bridging concept for casting these within more comprehensive high-level social theories [@raab1984; @smith2015, 22; see also @lucas2015 for nuances on this]. High-level theories can on this view be understood as \'overall perspectives from which one sees and interprets the world\' [@abend2008, 179], with examples frequently encountered in archaeology being practice theory, cultural evolutionary theory, and so on. Popper was concerned with establishing how Marxism and Freudian psychoanalysis were unscientific, as they are compatible will all empirical variation. However, @godfrey-smith2003[71] holds that attempts at determining whether Marxism is scientific or not is a mistake. Rather, a given instantiation of Marxism -- a Marxist model on the view taken here -- should risk exposure to observation and have the potential to be falsified in a given context. One way to see models is thus as bridging concepts representing concrete instantiations of abstract theories, and as machinery for casting data as evidence to be confronted with these theoretical constructs.

In a realist conception of models, these can thus be seen as analytical tools, the purpose of which is to provide a concrete representation of the researchers beliefs, used to isolate or create a closed and credible surrogate system where causal mechanisms are allowed to work without impediment from surrounding noise [see e.g. @sugden2000; @sugden2009; @cartwright2009; @m√§ki2009 for discussion and variations on this]. The aim, according to @cartwright2009, is to reveal the capacities and differential contributions of unimpeded causal effects within such an idealised structure. However, this does not mean that the causal contribution is necessarily stable outside the surrogate system. In an open target system, the complex interplay of several causal mechanism can render the contribution from the modelled causal effects completely transformed, compared to their role in an idealised surrogate system [@gibbon1989, 150]. Although stable correlations can point to the possible existence of a causal relationship, the relevance of the realist study of capacities, unlike positivist regularities, does not presuppose closed target systems (Groff 2004:12--16). Positivism can be seen as necessitating a closed system with regular conjunctions between events, such that an event of type A is always followed by an event of type B [@gibbon1989, 149]. @cartwright2009 contends that even though the realist surrogate system is credible, in the sense that the mechanisms could conceivably occur and result in the phenomena in question, the system is almost always different from all real cases in ways that matter. Drawing on the oft-invoked *ceteris paribus* statement -- all other things are in fact not equal (cf. Cartwright 2003[1983]:44--47) -- all models are wrong. The confrontation of model and data can therefore never avoid the problems of induction, and the question of interest then is not whether the model is true or false, but if the model resembles the world in the relevant dimensions, given its purpose [@clarke2007, 747; @kohler2007, 3].

For all the ambiguities nested in the above account of what can be taken to constitute models, a central element is the view that they are constructed and explicit representations of our beliefs. Precisely this is also central to the contention that one of the most important aspect of model-based approaches follow from their explorative side [@hausman1992, 77; @aydinonat2007; @premo2010]. This results both from the assembly process itself, and from subsequent probing and manipulation of the model [@morrison1999]. In the initial construction of a representation of theory and data, the researcher is forced to concretise their assumptions and beliefs. This will likely lead to the adjustment of inconsistencies, the discovery of additional theoretical implications or relevant empirical patterns, and increase the opportunity for explicit handling and reporting of uncertainty. Through stringent and explicit aggregation of model features, further theoretical and empirical consequences are also likely to be revealed. Thus, in its construction, the model will already have provided valuable insights, regardless of its future archaeological life-span. 

Following its construction, further insight can be achieved through direct manipulation of model parameters and assumptions [@morrison1999, 32--35]. This holds the potential of revealing additional causal propensities and limitations that are difficult to reveal by passive study of the model, and can reveal how sensitive it is to such adjustments [@gibbard1978; @premo2010]. It has been argued that the potential of mathematical and computational models to stringently and coherently aggregate a multitude of mechanisms, and allow these to dynamically interact over time means that these can reveal unnoticed or counter-intuitive aggregate effects [@lake2014; @lake2015; @aydinonat2007], in effect generating new evidence that could not be discerned otherwise [@wylie2017]. The same exploratory potential is then extended by any attempts at evaluating the correspondence between model and target system, and by the involvement of an audience that comments, criticises, dismisses or helps align model and target system [@m√§ki2009].

A further central point for many advocates of a model-based archaeology has been how this. By adjusting a model until it fits the data. the the issues of equifinality and underdetermination informs a view in which emulation of a process that accounts for the empirical variation of interest is not an adequate inferential aim if the goal is to reach true explanations of the past [e.g. @premo2005; @premo2010; @lake2015, 23--24]. As multiple processes could likely account for the empirical patterns under study, mere emulation does not tell us what competing explanations are viable alternatives, and does not provide any basis for evaluating the likelihood that a proposed explanation should have resulted in the observed outcome.

## Inference to the best explanation

So far induction has here been used to denote all non-deductive reasoning, and been exemplified by what is sometimes termed its enumerative or statistical form. That is, induction as the repeated observation of conjoined phenomena. However, other forms of non-deductive inference exist. Archaeology is often, if not most often, concerned with explaining singular or infrequent events, and not generalisations where an appeal to enumerative induction is possible. Clearly then, other lines of reasoning can be drawn on to arrive at and choose between alternative explanations. One such form of inference has been variably labelled abduction, explanatory inference or inference to the best explanation [@godfrey-smith2003, 39--44; @harman1965; @lipton1991]. @lipton1991[58] formulates this mode of inference simply as 'Given our data and background beliefs, we infer what would, if true, provide the best of the competing explanations we can generate of those data.' [@fogelin2007, 604]. Scientific realist often lean on this mode of inference to provide a way around the problems of induction and underdetermination [@psillos1999, 162--182], and this has been argued to constitute a good and often inadvertently employed framework for archaeological inquiry [e.g. @fogelin2007; @campanaro2021].

@fogelin2007 argues that despite the theoretical differences that exists among archaeologists, inference to the best explanation is often the logic underlying their conclusions. For example, he demonstrates how when providing an explanation for smudge pits, a common archaeological feature in Eastern United States, @binford1967 draws on ethnographic analogy to arrive at an explanation that is better than any alternative explanations he can muster [@fogelin2007, 611--612]. Despite using deductive-nomological language, Binford never independently tests any deductively derived hypothesis, and he arrives at his conclusion, @fogelin2007[612] argues, because it is the explanation among the alternatives that corresponds with the widest breadth of relevant empirical data. Similarly, @hodder1991, after having abandoned his most relativistic stance, adopts what he terms a 'guarded objectivity' through an appeal to hermeneutics. This starts with the context of the archaeologists themselves and their pre-existing beliefs and underlying theories, which is opposed to the context of the people responsible for the archaeological material available to us. By moving back and forth between such context and trying to cast our data in the light of these, the goal is to adjust an interpretative whole until the two contexts coalesce. The process is thus one of iteratively fitting empirical pieces within an interpretative whole, that is at the same time adjusted by these pieces. In this framework 'We measure our success in this enmeshing of theory and data (our context and their context) in terms of how much of the data is accounted for by our hypothesis in comparison to other hypotheses.' [@hodder1991, 8]. This is arguably also an appeal to inference to the best explanation [@fogelin2007, 612--614].

Central here is that hypotheses have been argued to be best evaluated when comparing them to the ability of substantive competing alternatives to fulfil the same purpose, and not just their negation, the null-model [e.g. @smith2015; @wylie2002, 95; @perreault2019, 1--22]. Pitching alternatives against each other will lead away from a pure search for corroborative evidence for a single hypothesis, and will, following from Chamberlin's [-@chamberlin1897] 'method of multiple working hypotheses', help the researcher avoid 'a pressing of the theory to make it fit the facts and a pressing of the facts to make them fit the theory' [@chamberlin1897, 843; see also @platt1964; @betts2021]. This thus avoids one of the dangers of *post hoc* accommodative arguments, which has been argued to lead to explanatory complacency and personal attachment to individual explanations [@smith2015; see also @elster2015, 12].

However, if one arrives at hypotheses that account for the data equally well, that is, they are underdetermined, then other criteria will dictate what is the best choice among them. These are often termed theoretical virtues, which when combined is to capture the explanatory power of an hypothesis [@psillos1999, 171]. A first criteria pertains to explanation, where a realist would hold that an hypothesis that makes claims about what has caused an empirical pattern will be given preference over an hypothesis that does not. If a locational model says that sites tend to be located close to rivers, and another explains this with reference to a specific kind of resource exploitation practice, then the second hypothesis would be given preference. Apart from the realist goal of explanation, this follows from the additional empirical implications this causal explanation holds, thus potentially increasing it's explanatory breadth and increasing it's falsifiability. From a Popperian view, it is more risky. Other and interrelated virtues pertains to coherence with established theories, the power of an explanation to unify multiple theories in a comprehensive whole, the consilience of multiple lines of evidence, lack of *ad hoc* explanatory features, and ability to generate novel predictions [@psillos1999, 171]. Simplicity is also often held to be one such theoretical virtue [@fogelin2007; also discussed by @lake2015], although it is not necessarily clear why reality should be simple rather than complex [@godfrey-smith2003; see also @sober2015].

## Evidential scaffolding

Theoretical discussions in archaeology have often framed the field as situated at extremes of positivism and relativism, or humanistic and scientific ideals, harking back to Snow's [-@snow1959] distinction between 'The Two Cultures' in western academia [e.g. @earle1987; @s√∏rensen2017]. However, @chapman2016 and others [see below and @fogelin2007 above] have argued that this perspective does not inform how archaeology has in fact progressed, nor that it constitutes a good reference frame for understanding how to do good archaeology. This is not to say that these discussions cannot hold important points for elucidating the nature of our inferential frameworks, or that theoretical stances do not influence what questions are deemed of interest and how the material record is approached. Rather, this then in a sense naturalistic argument is that these discussions are over-simplified, hyperbole and largely unrepresentative of an archaeology that generally progresses by drawing on a far more complex and eclectic web of theoretical and philosophical influences [see also @hegmon2003; @johnson2006; @pearce2011; @preston2013]. Therefore, the extremes of insisting on trying to establish deductively certain knowledge or a whole-sale rejection of the possibility of ever moving beyond speculation does not represent an adequate reference frame for understanding what constitutes good archaeology, how to conduct it, nor how consensus and synthesis on claims about the past have been arrived at in the past.

Given the realisation that we lack an infallible logical foundation with which to establish explanations, @chapman2016 speak for an iterative epistemological process where a temporary scaffolding for how data is cast as evidence by drawing on multiple methodologies and lines of reasoning is continuously adjusted, extended and reassembled. Crucially, these scaffolds are to be subjected to critical reflexivity, but be grounded in domain-specific norms of what constitutes evidence, so as to tackle what @binford1981 [21] presented as the challenge of 'how to keep our feet on the "empirical" ground and our heads in the "theoretical" sky.' [@chapman2016, 8]. They further draw on @norton2003 to argue that progression in science has been achieved mainly through the domain-specific development of robust reference frames for grounding further inference, not through the development of increasingly sophisticated universal inferential schemas [@chapman2016, 39].

By drawing on @toulmin1958[213], who argues that we should 'abandon the ideal of analytic argument' and the goal of deductive certainty, a central component of Chapman and Wylie's [-@chapman2016, 36--37] argument is illustrated by a quote from @toulmin1958[248]: 

>'The proper course for epistemology is neither to embrace nor to armour oneself against scepticism, but to moderate one's ambitions -- demanding of argument and claims of knowledge in any field not that they should measure up against analytic standards but, more realistically, that they shall achieve whatever sort of cogency or well-foundedness that can relevantly be asked for in that field.' 

Important here is therefore that there is no universal recipe for inferential adequacy, but that inference is domain specific. What we can hope to achieve is that our inferences are credible, but this limitation should not entail a regress into whole-sale scepticism. The goal is to arrive at beliefs that are more reasonable to trust than doubt, without demanding that they should be infallible and beyond critical scrutiny.

Building on the theoretical plurality of archaeology, and echoing the point made by @godfrey-smith2003 referenced above, @chapman2016[41--43] argue that theory-ladenness will differentially impact what archaeologists consider evidence. Some biophysical observations will be relatively transferable between contexts, and their role as archaeological evidence less integrated with theoretical preconceptions. Inferences to do with symbolic behaviour is less transferable as they will be less secure, and more contingent on the given cultural context and the evidential scaffolding surrounding them to be considered evidentially adequate. However, this does not mean that symbolic behaviour is in any sense more off-limits than for example chronological inferences that draw on radiometric dating. Neither can reach deductive certainty, and their role as evidence for past events is simply differentially dependent on the warrants and assumptions that underlie them [@chapman2016, 42].

Following @toulmin1958, warrants are here understood as bridging concepts that allows one to move from observed data to explanatory claim.

While the inferential virtues outlined in the section above can constitute some guiding principles for how to arrive at good explanations,  @chapman2016 hold that these cannot be schematically and universally brought to bear on archaeological explanation. Different questions will necessitate different evidence, and different evidence will necessitate different warrants. What Wylie [-@wylie2017; @chapman2016] has held as a central component of evidential scaffolding is that these should be robust and draw on multiple lines of evidence. In his review of @chapman2016, @currie2017 likens this with the view of @cartwright2015 who prefers arguments that are 'short, stocky and tangled' over elegant and tidy arguments that are 'tall and skinny'. That is, at the price of complication, a diverse and broad evidential foundation is more secure than an elegant but fragile chain of evidential premises [see also @currie2017a; @bayliss2015].

## Quantitative archaeology and models

The understanding of archaeological inquiry outlined above need not be cast within a model-based understanding. The term model has been noted to increasingly involve aspects that were previously seen as a domain of theory [@preston2013, 10], and aspects of their role as conceived of here also relate to and cannot necessarily be set apart from other bridging concepts such as hermeneutics, Mertonian middle-range theory and evidential scaffolding. Furthermore, it has also been argued that models are best understood as a separate and distinct kind of reasoning [@godfrey-smith2009] and that models should not be conflated with all kinds of 'representational vehicles'[@godfrey-smith2003, 186--189].

However, despite its ambiguities, I still believe the model term offers a sensible way of thinking about the issues dealt with in thesis. It forces a view where explanations are cast as fallible explicit constructs, which are thus both more easily interrogated by me and others, and are less likely to lead to explanatory complacency. Furthermore, this concretisation and fallibility is also very much compatible with the ideals of open science. Precise and explicit constructs of our beliefs as interrogative machinery lends itself well to a transparent and cumulative research endeavour as these are more readily communicated and disseminated.

Furthermore, this view also directly maps on to developments in statistics, where a model-based framework has increasingly been argued to constitute a better and increasingly more dominating framework than the traditional null-hypothesis significance testing (NHST) approach, which has dominated much of the discipline for the last century or so [e.g. @burnham2002, 1-22; @rodgers2010; @mcelreath2020, 1--17]. To briefly run through this argument, the epistemological basis for NHST starts with assuming a null hypothesis under which chance alone has generated the data, or that there is no meaningful difference between two compared groups. If under some statistical model the observed data is found to be unlikely to be in compliance with this null hypothesis, then the alternative hypothesis, that of the researcher, is favoured. Many authors have pointed to the severe limitations of this approach over the years [e.g. @rozeboom1960; @cohen1994] -- a critique that has gained renewed vigour with the replication crisis that has impacted large swathes of the social sciences [e.g. @nuzzo2014; @wasserstein2016].

Some central issues is that rejecting the null hypothesis does not give logical support to the alternative, nor does failing to reject the null give logical support to the null. Multiple random or neutral processes can be responsible for the data, and data inconsistent with chance can be the result of multiple non-random processes -- a decision concerning the rejection of the null therefore gives limited, if any, explanatory insight. This follows from what is considered the backwards logic of NHST, as it evaluates the probability of the data given the hypothesis, not the probability of the hypothesis given the data. The probability therefore does not concern the veracity of the hypotheses themselves. Additionally, a large enough sample size will always lead to a rejection of the null [@cohen1994]. As @tukey1991 [100] put it 'the effects of A and B are always different -- in some decimal place -- for any A and B. Thus asking "Are the effects of A and B different?" is foolish'. Statistical significance is not equivalent to substantive significance, as the magnitude of the probability associated with a NHST test does not necessarily have any bearing on the size, importance, or lack thereof, of a substantive effect. Furthermore, this kind of dichotomised view of significant/non-significant is argued to often be equated to the truth of an hypothesis, and once a result is reached, subsequent substantive interpretations can quickly extend beyond what the significance test itself warrants [see @crema2022; @timpson2021 on this point in the context of demographic modelling in archaeology].

Some measures to counteract these issues is an increased focus on estimation and fuller reporting of statistical power, effect-sizes and confidence intervals, as well as a focus explicating the processes we believe underlie the data. This is argued to be facilitated by a model-based statistical understanding, an understanding that @rodgers2010[1] argues underlies a \'quiet methodological revolution, a modeling revolution\' that has been taking over the field. He illustrates the concept by example of the arithmetic mean of a distribution [@rodgers2010, 4]. Under the NHTS this is typically denoted a descriptive statistic. In a modelling understanding, the mean can instead be conceived of as one of many possible mathematical models for the data, with the mean being a representation of the central tendency of a distribution. The shift to a model-based perspective leads to the questions of whether this model achieves what the researcher is interested in, and whether it does so better than it's reasonable competitors, which in the case of the mean could be the median [@rodgers2010]. Put differently, the map is never the territory, but an abstract model such as the subway map can prove highly useful for the purposes of commuting, and more useful for commuting than a topographic map [@clarke2007, 742]. Echoing the point made above, we should therefore not evaluate our hypothesis against a null model, it's negation, we should instead cast it against alternative models for fulfilling the same purpose.

The importance of estimation and model evaluation over significance testing has also been promoted in archaeology over the years [e.g. @cowgill1977; @buck1996], and a concern with multi-model inference and model comparison is increasingly evident in the literature [e.g. @eve2014; @dinapoli2021; @timpson2021]. In a similar vein to @rodgers2010, @kohler2007[3] have argued that a drift towards model-based inference has also been quietly happening in archaeology. Furthermore, given the view that the goal is to compare the explanatory power of viable alternatives, not focus on building and corroborating single monolithic explanations, this model-based view is also compatible with Fogelin's [-@fogelin2007] argument that in practice, abduction is the form of reasoning that underlies most archaeological inference, whether this is acknowledged or not.

In closing, the model-based understanding outlined here thus builds on the realisation that data is influenced both by the world and what we believe about it, and that the fallible beliefs we have about the world are built by entire research communities over time. Furthermore, this model-based understanding not only involves the recognition of the necessity of simplification, but is, to repeat @jarman2000[320], to \'embrace the intellectual imperative of abstraction\'. As fallible constructs, the goal is to arrive at a model that is better than any competitors we can muster, not ones that are deductively certain. By extension, a model-based approach is therefore concerned with being transparent and precise in the arguments and assumptions that are being made, and therefore represents a strategy that both helps the modeller clarify their inferential framework to themselves, and facilitates critical engagement by others. Furthermore, as was indicated towards the end of this chapter, casting our questions in this light is also directly compatible with a wealth of techniques in quantitative research more broadly, in which an increasingly model-based understanding recognises and helps handle and make explicit the subjectivity, ambiguity and uncertainty in our proposed explanations [e.g. @flora2018; @mcelreath2020].

<!--chapter:end:04-models.Rmd-->

# Modelling the Norwegian Mesolithic

The last chapter laid out the foundation for what can constitute components of a model-based archaeology. This chapter will explore how casting the papers of the thesis in this light can help elucidate assumptions and further lines of inquiry associated with the arguments made in the papers. Each paper is first presented using an evidential argument schema, following @toulmin1958 [see @chapman2016]. Subsequently, a suggested causal model for the main components of each paper is presented in the form of directed acyclic graphs [DAGs, e.g. @morgan2015].

## Evidential argument schema

In the following, the presentation of each paper starts with laying out an evidential argument schema for the central evidential claims being made in the papers. The purpose of this is to clarify the argument being made, highlight central and potential objections and uncertainties, ways in which the study account for these, and ways in which this could be done in future studies. The components of the argument schemas is presented in Figure \@ref(fig:argument).


\begin{figure}

{\centering \includegraphics[width=1\linewidth]{figures/argument_ex} 

}

\caption{Outline of Toulmin's argument schema. The figure is based on Chapman and Wylie (2016:fig.1.1, 33--40) and Toulmin (1958: 94--145).}(\#fig:argument)
\end{figure}

Some adjustments to this framework have been made here. First, I have added the category \'potential backing\'. These are meant to indicate steps that might be taken in future studies to further accommodate rebuttals and to further strengthen the belief that the warrants hold. Secondly, drawing on @chapman2016, the category \'deflection\' indicates cases where I argue that rebuttals can be disregarded either due to a assumed limited impact or due to the challenges involved in properly accounting for them. That is, in these cases the rebuttals are not met with additional backing. Finally, the category \'qualifiers\' from Figure \@ref(fig:dag) is not included, as there were no grounds on which to properly assess the strength of the evidential claims being made.   

In the presentation of the papers below, these schemas will not be complete, but draw on what I view as the most central components of the arguments. Further nuances and caveats can be found in prose in the papers themselves, while the data and code published with each paper also offer further sources that can be scrutinised for additional underlying assumptions and potential inconsistencies. 

## Directed acyclic graphs

The second part of the presentation of each paper involves constructing a causal graph that explicate what I believe 

No extensive presentation of causal graphs is given here, and as they are only presented as suggestions that can potential structure future studies, their full potential is far from being utilised here [see e.g. @morgan2015; @mcelreath2020]. It is nonetheless necessary to establish some terminology. DAGs is a specific kind of causal graph, where the term \'directed\' refers to the rule that causal effects cannot be bi-directional -- that is, causes points to effects. \'Acylic\' refers to the rule that no directed path can form a closed loop. Causal graphs involving cycles and feedback-loops can be accommodated, but @morgan2015[80] recommend establishing empirically tractable directed graphs in most settings. To illustrate the concept, a simple DAG is given in Figure \@ref(fig:dag). 

The direction of the arrows (edges) in the model illustrates what variables (nodes) have an effect on other variables. An arrow going directly between two variables means that there is a direct effect. A is therefore said to have a direct effect on both B and D in Figure \@ref(fig:dag). C also has a direct effect on A, but as A impacts both, A is a confounding variable. That is to say, part of the impact of B on C may simply be the result of A affecting both. Finally, the effect of a variable that goes through one or more other variables is said to be mediated by the intervening variables. Part of the effect of A on C is indirect as it follows from its effect on, which in turn impacts C directly. 

DAGs are an effective tool for clarifying research questions, for explicating relevant concepts, and to identify assumptions. Furthermore, provided the variables can be sensibly operationalised, DAGs offer a precise statement of how the interrelation between variables should be modelled statistically so as to correctly estimate causal influences while removing effects that confound this estimate.  


If there is a direct effect between A and B, but variable Z also impact each of these, Z is said to be confounder. An arrow from variable A to B that go through one or more other variables indicate that the effect of A on B is mediated by the intermediate variables. A central element of this model is that the effect of the other variables on the distance between site and shoreline are all mediatated through the exposure of the site to the surroundings and accessibility to and from the site.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{figures/dag_ex} 

}

\caption{Example of a simple causal model presented as a directed acyclic graph.}(\#fig:dag)
\end{figure}

## Modelling the relationship between Mesolithic sites and the prehistoric shoreline

In the first paper of this thesis I have proposed a method for shoreline dating Mesolithic sites on the Norwegian Skagerrak coast, based on an empirically derived model of the relationship between the sites and the prehistoric shoreline [@roalkvam2023]. This was based on simulating the distance between sites and the shoreline using 66 ^14^C-dated sites and local reconstructions of shoreline displacement. The ^14^C-dates thus operates as evidence for site-use that is independent of the position of the shoreline at the time, effectively offering a way to test and quantify the long-held belief that coastal Stone Age sites in Norway were located by the shoreline. The study found the sites to typically be located on or close to the shoreline up until some time just after 4000 BCE, when a few sites are located further from the shoreline. At around 2500 BCE there is a clear break, and the sites are from this point on situated further from and at variable distances from the shoreline. Building on these findings, the likely elevation of sites dating to earlier than 2500 BCE were, in aggregate, found to be reasonably approximated by the gamma function given in Figure. This is the model that forms the foundation of the proposed method for shoreline dating, which is released as an R package with Paper 2.

The evidence and arguments underlying the study are presented as an argument schema in Figure \@ref(fig:t1). This centres on six major warrants that are necessary foundations for the evidential claim to hold. The first of these, Warrant 1, pertains to the radiocarbon dates from the sites and whether these correspond to the typological indicators in the lithic inventory of the sites, or should for some other reasons be disregarded as not being related to the occupation of the sites. For the paper, this choice was largely based on following the discretion of the archaeologists who have undertaken the excavations. Excluding these dates substantially increased the degree to which sites were found to have been located by the shoreline, and thus functions in support for the evidential claim. A potential concern could be that the fundamental premise of Norwegian Stone Age archaeology that coastal sites were situated close to the shoreline, might have impacted how these dates are treated in the excavation reports. A brief presentation of the dates and the arguments for why they are believed to correspond or not to the use of each site is provided in the supplementary material to the paper, so as to offer more transparency to this evaluation (Backing 1.3). While I believe this procedure to be adequate and the interpretations in the excavation reports to generally be sensible, it might be worthwhile to predefine a set of evaluation criterion for the quality and relevance of the ^14^C-dates if a similar study was to be undertaken in the future [Potential backing 1.4, following e.g. @seitsonen2012]. This would reduce the degree of *ad hoc* assessment of the dates.       

A related point that is not included in the schema that is worth commenting on is how several radiocarbon dates from a single site were treated. Dates not intersecting at 99.7% probability were seen as representative of unrelated occupation events. Intersecting dates were then modelled using the OxCal function Boundary, and then summed. However, the procedure of summing dates is argued by some authors to be difficult to justify statistically, and procedures for defining the likely start, span and end-dates for occupational phases might be more sensible. Furthermore, typological indicators in the assemblages could also have been included in the model, thus potentially offering a further backing to Warrant 1.

Warrant 2 pertains to the geological reconstructions of shoreline displacement and the interpolation between these to the sites. This is a necessary premise for it to be possible to evaluate the correspondence between site-use and the sea.   

\begin{figure}

{\centering \includegraphics[width=0.95\linewidth]{figures/toulmin_p1} 

}

\caption{Central evidential arguments underlying Paper 1 and 2, presented as a argument schema drawing on Toulmin (1958) and Chapman and Wylie (2016).}(\#fig:t1)
\end{figure}

In one sense this model is instrumental as the *reason* for the location of the sites has not been considered explicitly. By combining the present altitude of a site, its likely elevation above the shoreline when it was in use, and local shoreline displacement curves, this model makes it possible to assign a probabilistic absolute shoreline date to coastal sites in the region. On a realist view, however, it is still true that the treatment of the data and the conception of the model followed from an underlying belief of what mechanisms shaped the patterns in the data deemed relevant. While the model and derived method can be viewed as a instrumental dating tool, they are determined by the proclivity for sites to be located on the shoreline. As such, they are likely to be tightly integrated with both overarching cultural developments, as well as behaviour at the site level. By extension, the multitude of factors that can have shaped the site-sea relationship on the large and small scale, both temporally and spatially, offers a challenging causal web of possible interacting effects that ultimately determine this relationship. Having first derived this largely instrumental model, it gives opportunity to further test it's correspondence with other empirical data, and explore and expound underlying theoretical assumptions and implications. 

To illustrate this, below I have constructed a suggestion for a causal model concerning what determines the vertical distance between coastal Mesolithic sites and the shoreline in south-eastern Norway. 

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{figures/dagitty_p1} 

}

\caption{Sugggested causal model for the drivers behind the relationship between site location and the prehistoric shoreline in Mesolithic south-eastern Norway.}(\#fig:d1)
\end{figure}


A likely important factor for how exposed and accessible a site could be is the purpose of the visit to the site. The purpose of the visit is therefore given a direct effect on exposure and accessibility. For example, is the site meant to be used as a stop to rest and repair tools, to be used as a hunting camp or a location from where to acquire raw-materials for tool-production? Is it a base-camp for the entire residential group from where further forays are made, or is it meant to be a meeting place for several groups? The purpose of the stay is likely also to impact the length of the stay, which in turn might have implications for how close to the shoreline the site is established. A longer stay could for example mean that the site is more withdrawn from the shoreline, so as to make sure storm surges do not reach the site. 

Means of travel is also included in the model. Most travel in the coastal region is assumed to have been by boat in this period, which means accessibility to the site from the sea is likely to be of concern, as well the ability to safely beach and store the boats. However, some travel was also likely done by foot, for example from a base-camp to a site close by for gathering and processing resources such as shellfish, where the need for the carrying capacity offered by boats might not have been necessary. Travel by sledge on the ice is also a possible alternative. Not having to land boats could presumably have implications for how exposed and accessible a location could be.

The season also presumably has implications for how often one had to establish camp, possibly reducing mobility in colder periods. The season might also have implications for the kinds of dwelling structures that were necessary to erect, and likely determines the kinds of resources that were exploited, thus potentially impacting the purpose of the stay. The season is also believed to have implications for the degree of wind and wave-action at a location, thus affecting the exposure of the site to the elements, and impacting accessibility. Finally, the season presumably also has implications for the means of travel, for example by enabling the use of sledges in winter-time, and reducing the potential use of boats. Season is therefore given a direct effect on all of these variables.

Some variables and nuance that have been left out of the model are worth commenting on. The weather is for example likely to impact a lot of these factors, but is near if not entirely impossible to determine archaeologically. Furthermore, the purpose of the stay is here indicated using a single variable, but a stay need not, or perhaps likely did not, have a single purpose. A simple example might be a case where multiple kinds of resources were to be exploited from a site. A possible alternative would be to operationalise these as individual variables, where for example the magnitude of seal-hunting and the gathering of hazelnuts to be done from the site is kept as separate variables. These would in turn likely be determined by factors such as the density of these resources in the landscape, their caloric return, their cost in terms of handling-time and -energy, and the potential prestige associated with hunting a specific species or the accruement of enough food to allow for sharing. 

Furthermore, the entire picture is also further complicated by other latent variables that are left of the model. Social structure, overarching mobility patterns, territoriality, group size and composition, as well as religious beliefs could all impact land-use, site-structure and ultimately how sites were positioned relative to the sea. The proposed causal model thus pertains to what can be termed proximal causes  

However, I still believe the model forms a reasonable starting point and that it has the potential to reveal some important and true causal determinants for the site-sea relationship. A central challenge is of course how these factors are to be operationalised and determined archaeologically. The exercise of setting up the causal model is nonetheless useful in its own right, if not simply by forcing me to think through and concretise what elements I believe are important, and how these are related, but it also forms a framework that dictates how these variables would have to be handled statistically. 

### Operationalising the site-sea model

A central challenge for the proposed model is of course how the different variables can be measured. For example, determining the season for when a site was in use is possibly an insurmountable challenge, but some avenues for investigation exist. The most immediate line of evidence is drawing on faunal and vegetational material from sites. Depending on what resources were exploited this could make it possible to discern in what season the sites were in use  [e.g. @bergsvik2011]. Furthermore, @solheim2016 speculated whether what they identified as a predominance of fish on sites located in outer coastal areas, as opposed to terrestrial osteological material at sites in inner coastal areas, could reflect seasonal movement patterns. As bone is typically poorly preserved in the acidic Norwegian soils, this is a challenging line of evidence to draw on, but if this could be shown to consistently correspond to other site features, it could possibly be extended to sites were bone is not preserved. 

Similarly challenging is determining the means of travel. While boats can be reasonably be assumed to have been the main means of transportation throughout the Mesolithic in the coastal region, it has been suggested that sledges and skis could have been used in inland areas [see @s√∏rensen2013]. The relevance of these alternatives has to my knowledge not been extensively explored in the context of coastal Norwegian Mesolithic archaeology. Thus, although the relevance of this variable is therefore not certain, and these suggestions remain speculative, one line of reasoning could be an analysis the topographic location of the site, possibly also combined with insights into resource use and site function.

When it comes to measuring the length of stay, it was suggested the third paper of this thesis [@roalkvam2022], as presented in more detail below, that aspects of the lithic inventories reflect the duration of stays at the sites under study. Assessing the distance between site and shoreline when accounting for these measures could therefore offer a way forward in this regard. While length and purpose of stay are likely to be tightly integrated, the analysis of lithic inventories also offer a clear possibility for establishing 

The exposure of Mesolithic sites was investigated in @roalkvam2020 using viewshed analysis to estimate visibility, and the estimation of wind-fetch to measure exposure to wave-action. A third potential way to handle exposure could be to devise a method for estimating the distance from the site to the outer-most coastal feature at the time the site was in use. Although all of these measures have seen limited or no previous application in Norwegian archaeology, they offer clear ways forward with which to investigate these issues.

Finally, accessibility is another challenging variable to operationalise that has not been explored much in the literature. Good landing places for boats are often pointed out in excavation reports and in the literature, but precisely what this entails is not always as clear and no definition has to . A common feature appears to be a gentle slope towards the prehistoric shoreline, which can readily be explored in a GIS. Presumably the exposure of the location to wave-action is another relevant measure here, and so there might be ways to fruitfully explore this as well.

As it stands the most readily implemented explanatory variables of the model is therefore the duration of the stays at the site, their exposure to surrounding landscape, and potentially the accessibility to the sites. The most challenging are those of seasonality and means of travel in relation to the sites. To conclude, this exercise has nonetheless demonstrated the value of suggesting an explicit causal model, and has laid out some potential avenues for further interrogating the issue of the relationship between coastal Mesolithic sites and the contemporaneous shoreline.

## Modelling the technological expediency of lithic assemblages 

The third paper of this thesis was focused on two analytical avenues. The first of these was using correspondence analysis to evaluate the chronological  development in the occurence of various artefact categories over time, which in large part appears to coincide with previous suggestions in the literature. The second line of 




Focusing first on its instrumental value, shoreline dating will often provide the highest resolution date that one can hope to achieve for a site, given that material to radiocarbon date is quite rare due to taphonomic loss, and as established typological frameworks in the region operate on the millennial scale. By facilitating a dating method, the model can thus be drawn on to explore traditional long-term chronological questions, such as the frequency of sites throughout the period [@roalkvam], the assessment of typological frameworks, or the timing and spread of various cultural phenomena, to give some examples. Furthermore, the finding that sites tend to be located further from the shoreline from around 4000 BCE and 2500 BCE, correspond with major socio-economic developments, where these dates roughly correspond to the first introduction and subsequent firm establishment of agriculture in the region. Although it still remains to be tested on data independent from where it was derived, the instrumental utility of the model is therefore clear.  

However, as it is difficult to determine the longevity of use and re-use of the open-air sites that dominate the Mesolithic record in the region, the number and duration of settlement events being dated in each instance is not clear. Previous consideration of these questions typically range from characterising the sites as the result of short visits of only a few hours up to a few months, and range from single visits to seasonal re-visits over a few decades---possibly centuries in the most extreme instances. However, given the resolution that shoreline dating provides, even at its best, the method does not by itself provide a precision high enough to weigh in on this issue, and can therefore not inform the number or length of stays within the determined date range. This has implications both for the questions that the method can be used to answer, and causal drivers behind site location that we can hope to disentangle using the model, given that these dimensions are likely to have been of importance for the location of the site relative to the sea.   [e.g. @bailey2007; @perrault2019]

Having established the model also opens up for a shifting of perspective back and forth from the large to the small scale, and from shoreline date to site location relative to the shoreline. Such an approach can illuminate implications of the model and its workings, and, in turn, potentially also feed back to and lead to a refinement of the model. One such example is now given by considering the location of the site Pauler 1, relative to sea according to the model.

The mean elevation of the site is masl. Based on the likely elevation of the site when it was in use, as informed by the shoreline model, the resulting shoreline date is. The benefit of having a model where all three parameters are clearly defined is that this allows us to shift perspective between the date of the use of a site and the implication this has for the relative position of the shoreline. Thus, looking now instead back from the calendar scale (the x-axis in Figure), to the likely elevation of the site above sea (the exponential function on the y-axis in Figure), and combining this with the elevation of the sea-level above it's present altitude at this time (represented by the displacement curve in Figure)--effectively rearranging the equation--thus allows for an instantiation of the model implications for individual sites in the spatial domain. In Figure, this is done by simulating the sea-level that the shoreline date implies.

Given the commutative nature of the relationship between shoreline date and the elevation of the site above sea-level, it is possible to translate directly between these dimensions and treat the resulting sea-level 

The model, while a reasonable approximation of the relationship between sites and shoreline in aggregate, could still be substantially off when applied to individual sites, as was demonstrated here by the in-depth analysis of Pauler 1. However, this model failure has to be qualified. First, the articulation and exploration of *how* the model is wrong has allowed for a further understanding of both the site and the model. Furthermore, this can also function in a step towards generating causal models explaining why, in any given case, the site was located as it was. While an immensely challenging task, this would   

The concept of shoreline dating touches upon such a wide range of issues that it can in sense be seen as a microcosm of archaeological inquiry as such. While physical sciences underlie the framework, as it is ultimately dependent on reconstruction of shoreline displacement, the question is inherently social and cultural. Furthermore, perspectives from a vantage of social and humanistic can not only be used to derive cultural significance from the observed patterns, but these can also be used to further improve the method for shoreline dating. My view is that this is defining of archaeology as a whole. While here nested in model-based archaeology, which I found a useful framework with which to think about these issues, I also think this illustrates the heterogeneous nature of archaeology and the value of drawing on multiple strains of evidence and perspectives. The iterative move between aggreagte model and individual cases could just as easily have been cast within a hermeneutic understanding of archaeological research. This also highlights the inadequacy of attempting to understand archaeological research as being situated somewhere on a scale between more or less scientific or humanistic, more or less processual or post-processual, as these are simply unable to capture the necessary nuance of archaeological inquiry.   

<!--chapter:end:05-meso-models.Rmd-->

# Conclusions and future directions

<!--chapter:end:06-conclusion.Rmd-->

<!-- # References {-} -->

<div id="refs"></div>

<!--chapter:end:07-references.Rmd-->

